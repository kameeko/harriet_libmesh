-> inverse prob for LF and HF; to avoid optimization algorithm, solve KKT system
  -> which adjoint system? stabilized adjoint or transposed of stabilized jacobian? for optimization problem where we care about a particular discretization, we want to use the transpose of the stabilized forward as the adjoint...
  -> is the adjoint of the stabilized system even the stabilized adjoint-of-unstabilized?
    -what is the meaning of the adjoint of a stabilized system anyways? the stabilization depends on the discretization...
      -> see supg_analysis.pdf
  -> what does the adaptivity theory rely on?
  
...aren't we inferring for a smooth source term, so regular stabilization should be fine?

debug:
nan residual?? after the linear solve...c doesn't seem to have moved from initial guess, based on qoi...also numerical and analytical jacobians don't match
  -> checking analytical jacobians takes a long time...on 46x33x3 mesh, two jacobians now match...still get nan...
  -> 5x5x3 should be small enough for matlab to read in without freezing...
    -nan whether supg toggled on or off
    -J is not full rank...311/432...fwd J was full rank, so shouldn't be about BCs of fwd+adjoint...
      -> if we view z as a forcing for f, then the gradient equation doesn't have a unique solution? is the regularization insufficient to make the problem well posed cuz it penalizes the gradient? is that why you chose forcing to be zero at boundaries?
      -> if f given homo Diri BCs, then J still not full rank (422/432) (485/504 for 5x6x3 mesh...)
      -> does giving either of the other BCs diri BCs fill up the remaining rank deficit?
        -f and c have homo diri: 352/432 O.o??
        -f and z have homo diri: 311/432
        -something wrong in interior? if all have homo diri and side residual contribution set to zero, still get nan's
          -interior terms look the same as in old cd_all inverse system...
          -matlab says rank is 417/432; if velocity increased to 2.415 (remove e-5 factor), then matlab thinks it's full rank...scaling problem? even with inceased velocity, still get nan...
          -do not get nan if superlu used with regular velocity, but then qoi becomes negative...same for original non-Diri BCs...
            -superlu is not the way to go...on 92x66x5 mesh, even bassi chokes...doesn't finish after 30 minutes...
          -if using inputs for HF for long_channel_stash/qoi2_setup02/HF, recover recorded QoI using superlu, but also get nan residual using default solver; Jacobian on coarser mesh is full rank
          
    system    mesh    variation                             gmres           gmres w/shift           superlu       rank(J)       cond(J)
    nandbg    25x5                                    fails, resid e7                               resid e-17    468/468 **      e3
    nandbg    15x3                                    resid e-14                                    resid e-17    192/192 **      e3
    invLF     5x5x3   f homo diri, no supg            fails, resid nan                              resid e-10    422/432 (same with fixed beta/gradf signs)
    invLF     5x5x3   f homo diri, vel*e5, no supg    fails, resid nan                              resid e-9     429/432
    invLF     5x5x3   f homo diri, vel*e6, no supg    fails, resid nan                              inex newt fails, resid e-8)         
    invLF     46x33x3  f homo diri, vel*e6, no supg                         inex newt fails, (resid e-1) resid e-9
    invLF     46x33x3  f homo diri, vel*e6, no supg, disp 400               inex newt fails, (resid e-2) resid e-8
    invLF     46x33x3  f homo diri, vel*e6, no supg, disp 4000              inex newt fails
    invLF     5x5x3   all homo diri, no supg          fails, resid nan                              resid e-7     417/432
    invLF     5x5x3   all homo diri, vel*e5, no supg  fails, resid nan                              resid e-7     432/432 **      e11
    invLF     5x5x3   all homo diri, vel*e6, no supg                        resid e-1 (9 order reduction)         432/432 **      e9
    invLF     5x5x3   all homo diri, vel*e6, #4 supg                        resid e-2 (10 order reduction)        432/432 **      e9
    invLF     46x33x3  all homo diri, vel*e6, no supg                       resid e-4 (11 order reduction)        
    invLF     5x5x3   all homo diri, vel*e5, no supg, disp 400              resid e-2 (10 order reduction)        432/432 **      e9
    invLF     5x5x3   all homo diri, vel*e5, #4 supg, disp 400              resid e-1 (9 order reduction)         432/432 **      e9
    invLF     5x5x3   all homo diri, vel/decade, no supg, disp 400          resid e-2 (9 order reduction)         432/432 **      e12
    invLF     5x5x3   all homo diri, option 4 supg    fails, resid nan                              resid e-7     417/432  
    invLF     5x5x3   f homo diri, option 4 supg      fails, resid nan                              resid e-9     422/432 
    nandbg    5x5x3   all homo diri, no supg          fails, resid nan                              resid e-7     417/432
    fwd       5x5x3   iso 40                          resid e-7                                     resid e-10    144/144 **      e2  
    nandbg    25x5x5  gave data z-coord, else same    fails, resid nan      resid e-9               resid e-16    TOO LARGE TO READ INTO MATLAB
    nandbg    15x3x3  gave data z-coord, else same    fails, resid nan      resid e-11              resid e-15    768/768 **      e3
    nandbg    15x3x3  gave data z-coord, just f diri                        resid e-12                            768/768 **      e6
    nandbg    15x3x3  gave data z-coord, just f diri, const v=0.5           resid e-11                           
    
    -nondimensionalize, compare current nandebug (put old nandbg params into invLF code?)?
      --wouldn't change the peclet number...is that what's really at the heart of f-homo-diri cases skimming singularity?
      -first implement last nandbg in inv_LF
        -sign on beta*grad_c and cpred-cstar were inconsistent...if match nandbg, then recover same qoi..if flip signs, then newton solve fails...
      -how to nondimensionalize with tensor diff? do you also scale domain?
        -without scaling domain, dividing by tensor*disp -> current nondimensionalization messes up 15x3x3 nandbg qoi...(should be 1.05191)
    -or maybe you really do need to go parallel?
    
    -> add pc_factor_shift_type nonzero:
    ./progname -ksp_monitor_singular_value -ksp_gmres_modifiedgramschmidt -ksp_gmres_restart 500 -pc_type ilu -pc_factor_levels 4 -pc_factor_shift_type nonzero
      -> singularity of J perhaps related to velocity term being too small relative to element size? maybe forward and adjoint, which only differ by sign of velocity, look too similar? no, one acts on adjoint and one acts on state...different columns...
        -> only velocity and reaction use time...
      -> on bassi
          92x66x3
            iso, all homo diri - almost 3 hours of "alive time", but only 6 minutes of "active time"...
            iso, f homo diri - 8.3 hours of "active time", but about 12.2 hours of "alive time"...
            iso, no diri
            aniso, f homo diri
            aniso, no diri
          184x132x4
            iso, f homo diri
            iso, no diri
            aniso, f homo diri
            aniso, no diri
        
bart told karen he has an example that would be applicable to master's and easy to apply in milo?
--> focus on getting the two papers written and submitted this semester before opening more cans...will help you narrow down your ideas and see what work can/should still be done...and to understand what it means to have something finished...you should be expecting to get 2-3 papers from thesis...

karen will be at mit 4/6-7

date for forming committee is a guideline...

----------------------------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------------------------

DO NOT EVER USE HARD RESET EVER AGAIN IT DOESN'T JUST APPLY TO SUBDIRECTORIES IT APPLIES TO THE WHOLE REPO

----------------------------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------------------------

bart didn't seem to have any actual model pairs in mind, just ideas for applications...batteries? also using summer cd(r)...

-if we want to compare linear solves, then need to make sure that linear solves are being solved precisely (especially with iterative solvers!)
-sometimes a newton solve with not converge if linear solves done precisely, but sometimes the looseness of inexact solve can save it (ex: continuation on HF cdr, 600->700 doesn't work if superlu used...)

-write up new error breakdown
  -RUN NEW ERROR BREAKDOWN WITH SCALAR VS FIELD
-ask if continuationsystem can be used for the desired purpose
  -yes, but arclength continuation is overkill...natural continuation is more common...calculating optimal parameter stepsizes would require tangent information of some sort, and at that point you might as well use arclength...which is meant for robustness, not necessarily for efficieny...
-streamline psi-to-superadj
  -how long does it take to set up meshes/system objects? if significant, is there a way to just reassign subdomain IDs? have all the divvy text available and read them in? (re-run from start-to-finish each time new divvy available)
  -reassign subdomain ID without changing current solution? keep that as initial guess?
  -seems like it might be lot less work to read in xda files like in superadj than to read in exo like in psi_MF...psi_MF had a lot of time spent in inverse_map() under FE...
    -is psi_MF also reads in psiLF_mesh.xda instead of exo mesh, time spent in inverse_map() doesn't change...
    -inverse_map() is called in relation to sensor points...not sure why called ten times more often in psiMF than superadj...
      -order of mag difference doesn't appear in psiLF iteration with R=-42...both spend considerable time there...
      -number of calls reduced to about 1/3 if only 1 of 3 datapoints kept, and yet if explicit calls counted, they only amount to hundreds, not millions...majority of explict call count also disappears if no numerical vs analytical jacobian comparison...
      -contains_point calls inverse_map...and you're calling that for every element...use PointLocatorTree to find and store element that points are in...
  -solution transfer hopefully doesn't take up too much? (nope it doesn't)
  -is it fair to not count refinement in timing? just cuz you're doing it in matlab...which is probably not the most efficient way either...
    -if we have a problem where the two methods are sufficiently different, it shouldn't matter...
  -can we make a basis function a vector of original basis functions? would that help with grouping basis functions by node?
    *****what if you just trust that every group of 6 belongs to the same node?*****
  
  -LF iteration, superlu: 
    split codes = 25+72=97 (10+51=61 in linear solve)
    joined code = 90 (63 in linear solve)
    joined code, split super-adj = 50 (20 in linear solve)

  -FOR FINAL COMPARISON:
    -turn off numerical jacobian check
    -turn off norm checks
    -use analytic velocity for both
    -be consistent with solver tolerances
    -close other programs...what's playing on youtube affects runtime...
    
-benjamin model thoughts:
  -combustion
  -stokes v navierstokes
  -ROM for LF? how to stitch? if a LF/MF linear solve is cheaper, than all the better...but how fares the theory?
  -time dependent oscillations - reactor tube or flow over clamped wing
  
  -> first try with scalar A, E? what about just inferring k, and not the parameters that describe it based on the Arrhenius eq?
  -> alternative to arrhenius equation? ("of Arrhenius type and modeled as in Cuenot and Poinsot")
    -alternatives to even having concentrations to powers? (vikram will look at this)
  -> field vs scalar E? hopefully field E makes things nonlinear enough to require many more nonlinear steps...
    -does it even make sense to make E a field?
    -what happened to previous attempts to limit scalar and field param variables to different subdomains?
      -see practice/T_channel/diff_param_res/all_linear/get_psi_MF_discon/debug_notes.txt:
  -> HF: couple non-newtonian flow? depends on temp...what sorts of reactants would this make sense for?
  -> HF: couple to compressible navier stokes? (density depends on temperature; varying density would also affect reaction expression)
  -> Galagali, Nikhil: thesis on different combustion models...
    -seems to be about inferring (stochastically) for intermediate reaction mechanisms (infer for pathway) and their reaction rates
  -> Rebecca Morrison: might have some knowledge of chemical model hierarchies
    -> nikhil and rebecca are both youseff's...maybe ask him?
  -> just make the LF a ROM? gah how to those work?
    -need HF fwd runs in order to build basis...that would probably have to be included in the cost of even creating LF model...
    -projection-based: let the solution only exist in subspace of R^n, defined by a not-full-rank basis; would affect state and adjoint, but not params...ROMs for inverse problems?
    -each component of the reduced basis is likely to have nonzero components inside and/or outside the LF regions...do we just ignore those bits that are outside the LF regions? pretend they were just given?
    -doesn't seem easily implementable in libmesh...though it does have a 'Reduced Basis' section in examples...
    -can theoretically still use a ROM, but will probably need specialized method to build the basis...
  -can we/would it make sense to infer temp from measurements of temp?
  -HF has additional reactions that also affect temperature? (instead of adding intermediate reactants, just have other species with their own reactions that also contribute to temp...)
    -ex: 2H_2 + O_2 -> 2H_2O, C + O_2 -> CO_2; C is a contaminant? (also N2+O2=2NO, 2NO+O2=2NO2)
      -if LF is assuming C = 0 (no carbon-oxygen reaction), then MF model will have 'pinning' in LF parts of domain...can have pinned value in initial guess?
    -pure-oxygen vs "air"? combust methane in oxygen vs in air?
    -impure mixture doesn't even need to be air...make up some contaminant...
      -NOx has complicated mechanism, and doesn't seem to have a simple version with O_2 instead of O
      -kinda weird, though, to know the params for your contaminants but not your main reaction...
  -if you knew the field for H_2 and O_2 and T, could you write equation for H_2O as convdiff with reaction term as source? infer for parameter describing inlet H_2 and O_2 (and inlet T?) and also parameterizing fields (say, you guess it'll look somewhat half-eliptic?), which thus parameterizes forcing?; measurements of H_2O or T?
    -if parameters can be used to create analytical expressions for H_2, O_2, T fields, couldn't you make this a ROM? basis depending on analytical expression, not derived from original FE basis functions?
    -parameters that affect diri BCs...how to derive adjoint, and is that something you could implement?
    -what if you do H_2 and O_2 fields without reaction, and read them in to create forcing function? based on assumption that H_2 and O_2 concentrations large enough so as to be mostly unaffected by reaction? 
      -if there is a shat ton more of one reactant than another, then the amount of product is limited by the availability of the scarcer species...can't quite divorce the product from the concentration of *both* reactants though...
    
-stokes vs navierstokes
  -parameters in b+v are actually not in diri bcs...would appear in weak form...
  -does it really not make sense to try to mesh stokes and navierstokes in one domain? at least, not have large parts of domain with the very different reynolds numbers...
-different physics + different mesh resolutions? HF: more nonlinear and higher resolution?
  -vikram poking whether libmesh can do this...-> yes
  
-does having localized reaction (as if other reactant(s) were available at only certain location, and which concentration was very large/kept constant; or as if catalyst sufficiently reduced activation energy only in some region) make the problem more nonlinear?
  -cdr solve, r = 400, centered at (2.5,0.5)
    -everywhere: 5 NL iters
    -r exponetially decaying, decay param 1:  5 NL iters
    -r exponetially decaying, decay param 10: 4 NL iters
    -r exponetially decaying, decay param 20: 4 NL iters
    -r exponetially decaying, decay param 20: 3 NL iters
  -it shouldn't...otherwise MF with cd+cdr would be worse...
    
  -what happens to the qoi if you remove data points altogether? (in chad's thing, there seemed to be the possibility of certain data points being ignored/not of much weight) how does the error breakdown change? what if you change the data values?
    -can we use this to say something about experimental design?
    -adjoints are about sensitivity to perturbations...sadj_auxc seems to indicate most sensitivty to data mismatch near middle sensor...?
      -sensitivity of what? error in qoi?
        -kinda seems to fit that interpretation...if you could only have one sensor in one of the three positions, then having middle gives lowest relative difference in QoI...if you had a right sensor and could only add middle or left sensor, then most reduction in relative difference in QoI if add middle...same if you had left sensor at first...relative difference increases from just-right to left+right, so is this even a good measure?
        
        
poke dissolution/precipitation forward problem, see if it does have an interesting steady state?
  -if not, then try **iso conv-diff vs aniso conv-diff-react**? or **inferring for k with regular cd vs cdr**?
  -try inexact-linear-solve continuation on original problem, vs newly integrated? does newly integrated benefit from loose linear solve?

is continuation not 'state of the art' enough because we would not normally even solve the whole KKT system, and instead go for optimization program? harder to compare the two then...although even for optimization a good initial guess is sometimes needed...

natural continuation vs integrated adaptivity: (strict linear solve, gmres)
  r = 0 inv: 4.5 (3 in linear)
  r = -442: cont steps (0,100,200,300,400,442) < adaptive (1 step, 0.11 final fraction) < cont steps (400, 442)
    -> 25 (15 linear ) vs 35 (23 linear) vs 40 (28 linear)
    -> 1 adaptive step, 0.11 final refinement fraction, 0.0144 estimated relative error, 0.0035 actual relative error
  r = -1000: adaptive < cont steps (0:100:1000) < cont steps (400:100:1000) < cont steps (0,400:100:1000)
    -> 43 (30 linear) vs 56 (35 linear) vs 67 (45 linear) vs 96 (72 linear)
    -> 1 adaptive step, 0.11 final refinement fraction, 0.0115 estimated relative error, 0.004 actual relative error
    -> this looks possibly promising...**do 3D version with iso conv-diff vs aniso conv-diff-react?** (same mesh first?)
      -ONLY RUN 3D ON BASSI

3D iso conv-diff vs aniso conv-diff-react
  -halve each dimension and origin-align? can do parallel for inv and fwd, but will make adaptivity more difficult (deal with elements across processors)
  -LF inv in serial with strict linear tol and 92x66x20 mesh takes 3+ hours (get stuck at e-10 residual for some reason...solves on 5x5x5, weird glitch in ssh?)
  -inv, quartered domain, 46x33x20, n=0.3
    -iso 100: 155 (141 in linear)
    -iso 40: 160 (147 in linear)
    -aniso 100-40-4: 220 (200 in linear)
    -aniso 100-40-4, r = +1e-3: 466 (433 in linear)
    -aniso 100-40-4, r = +2e-3: freaking forever
    -aniso 100-40-4, r = (0,e-3,1.5e-3,2e-3): 3392 (3140 in linear)
    -aniso 100-40-4, r = (0,e-3,1.5e-3,2e-3), v = nv: 21798 (20336 in linear; seems to have hit max NL iter?)
  -inv, quartered domain, 25x45x30, no stabilization (n in vel), n=0.3
    -iso 100: 160 (150 in linear)
    -iso 40: 158 (150 in linear)
    -aniso 100-40-4, r = (0,e-3,1.5e-3,2e-3), v = nv: 1117 (1043 in linear)
    -aniso 100-40-4, r = (0,1,1.5,2,2.5,3,3.5,4.2)e-3, v = nv: 2480 (2300 in linear); qoi: 547209.61
  -inv, quartered domain, 25x45x30, no stabilization (n in vel), n=0.1
    -iso 100, r=0: 159 (151 in linear); qoi = 1068855.6709150125
      error estimate vs 4.2e-3: -333214.34175340564
      error estimate vs 4.2e-4: -400936.34636102663
    -aniso 100-40-4, r = (0,1,1.5,2,2.5,3,3.5,4.2)e-3: 2470 (2300 in linear); qoi = 547417.81514302175
THERE WAS A BUG IN THE JACOBIAN OF HF CONTINUATION (REACTION TERM)
    -aniso 100-40-4, r = (0,1,1.5,2,2.5,3,3.5,4.2)e-3, jac-fix: 
      12135 (11724 in linear); qoi = 547420.85898380179
      (wow we must've gotten really lucky before with the wrong jacobian...)
    -aniso 100-40-4, r = (0,1,1.25,1.5,1.75,2,2.25,2.5,2.75,3,3.25,3.5,3.75,4,4.2)e-3
      22040 (21290 in linear); qoi = 547422.15360160533
    -aniso 100-40-4, r = (0,1,2,3,4.2)e-3, jac-fix: 
      7432 (7170 in linear); qoi = 547421.62359722063
    -aniso 100-40-4, r = (0,2,4.2)e-3, jac-fix: 
      6587 (6446 in linear); qoi = 547421.59753930464
    -aniso 100-40-4, r = (0,4.2)e-3, jac-fix:  
      6210 (6130 in linear); qoi = 547419.95996741741
THERE WAS ANOTHER BUG IN THE JACOBIAN OF HF CONTINUATION (REACTION TERM)...even though previous one passed jac check...
    -aniso 100-40-4, r = (0,4.2)e-3, jac-fix:  
      440 (413 in linear); qoi = 547417.92230248486
    -adaptive: (r = 4.2e-4), 0.1 steps
      MF01: qoi = 577581.79809296422; estimated rel error = -0.038311485179517969; actual relative error = -0.0522
        Final refinement fraction: 0.16651851851851851; if stop here, 1113 (1035 in linear)
        just inv, psiLF start: 338 (322 in linear); just inv, r=0 start: 317 (301 in linear)
      MF02: qoi = 548904.34911934205; estimated rel error = 0.002185847354112873; actual relative error = -0.002718
        Final refinement fraction: 0.29025185185185187; if stop here, 1795 (1672 in linear)
        just inv, psiLF start: 389 (374 in linear); just inv, r=0 start: 390 (374 in linear)
      MF03: qoi = 547773.23232645926; estimated rel error = 0.00032135133846412049; actual relative error = -0.000644
        Final refinement fraction: 0.42269629629629629; if stop here, 2222 (2050 in linear)
        just inv, psiLF start: 248 (232 in linear); just inv, r=0 start: 246 (230 in linear)
    -adaptive: (r = 4.2e-4), 0.05 steps (psi_and_superadj2)
      MF01: qoi = 613418.65290589374; estimated rel error = -0.066492866621420899; actual rel error = -0.1075915977
        Final refinement fraction: 0.0927; if stop here, 1040
        just inv, psiLF start: 267 (251 in linear); just inv, r=0 start: 265 (250 in linear)
      MF02: qoi = 558522.85455398832; estimated rel error = 0.002080804223470499; actual rel error = -0.019877534
        Final refinement fraction: 0.169; if stop here, 1864
        just inv, psiLF start: 402 (387 in linear); just inv, r=0 start: 393 (377 in linear)
      MF03: qoi = 550323.00719542312; estimated rel error = 0.0045611526719650146; actual rel error = -0.0052751566
        Final refinement fraction: 0.237; if stop here, 2417
        just inv, psiLF start: 266 (250 in linear); just inv, r=0 start: 251 (236 in linear)
      MF04: qoi = 548224.52965272486; estimated rel error = 0.0030239362458373475; actual rel error = -0.0014675915
        Final refinement fraction: 0.304; if stop here, 2965
        just inv, psiLF start: 328 (312 in linear); just inv, r=0 start: 344 (328 in linear)
      MF05: qoi = 547743.82753993955; estimated rel error = 0.0011951462532848933; actual rel error = -0.0005912756
        Final refinement fraction: 0.372; if stop here, 3309
        just inv, psiLF start: 248 (233 in linear); just inv, r=0 start: 247 (231 in linear)
      MF06: qoi = 547531.83860096941; estimated rel error = 0.00035427666447780811; actual rel error = -0.0002043327
        Final refinement fraction: 0.446; if stop here, 3642
        just inv, psiLF start: 246 (230 in linear); just inv, r=0 start: 287 (269 in linear)
  
THE LAST TWO REFINEMENTS HAVE THE WRONG SIGN...WAS THERE SOMETHING TWITCHY ABOUT OUTPUTTING c_points and aux_c points to file? weird seg fault during first run, if no such files already in directory...?
AAAHHH ADAPTIVITY WAS DONE WITH REACTION 4.2e-4, while continution was 4.2e-3...
  -> not a typo...one of the codes includes porosity in reaction term, the other doesn't...e-4 is with multiplication by porosity...
  
  is there a good way to show 3d error dist? error seems most concentrated near qoi region, makes everything else almost invisible...
====================================================================================
-from last time...
  -integrated adaptivity steps into one time-able code
  -model from benjamin - haven't come up with reasonable LF or HF model to go with it
  -continuation
    -natural continuation - more steps sometimes faster; can try a bunch of step sizes and pick best? or look for heuristics?
    -arclength continuation - seems to be commonly used in NL FEM solvers, but 'overkill' if no bifurcation; more about robustness than efficiency
  -3D porous media, combinantion of monty and nicer (but still in range of what's seen in porous media) alphas
  
-meaning of r? is there a non-dimensional version of r? either have units or non-dimensionalize? damenkoler number?
  -can you justify r?
-try a few more continuation sequences
-table of times and errors? (MF01, MF02, MF03)
-reactive turbulent combustion - turbulence is hard, as is the shat tons of intermediate reactions...
  -refinement of graphs? poke manishika about graph theory?
  
  http://chemwiki.ucdavis.edu/Core/Physical_Chemistry/Kinetics/Methods_of_Determining_Reaction_Order#Second-Order_Reactions
  p.683 of 'remediation of hazardous waste contaminated soils' by donald l. wise (scan of chapter requested from iliad)
  'Evaluation of the kinetic oxidation of aqueous volatile organic compounds by permanganate' 
    -total second order (two reactants); rate constants are O(e-8) at most...perhaps because aqueous and chemwiki reactions were gaseous?
  
  hmm...do you know anyone who might be able to help with the Damkohler number question? the expression on wikipedia is the most general I can find, but I don't know what the diffusive/convective 'mass transport rate' is in our equation...the reaction rate is change in concentration per time, so it has units [M/L^3/T] (Mass-Length-Time), but I'm not sure what in the convection-diffusion aspects of our equation has those units...the more specific reactions on the wiki page, as well as the other expressions I've found, seem to be derived for particular reactors and reaction orders (most assume first-order reactions, or particular idealized reactors)...
  
mind maps?
====================================================================================
  
field vs scalar error plots need colorbar readjusted to show more than just spastic fringes...
    -wow those fringes are really spastic...can we fix them? are they the source of the spaz in the error?
      -f and auxf aren't really oscillating at the fringes though..well pinned...
      -are the basis functions for blaming even done properly? at the boundaries, they would only be half a hat...
      -does the idea of 'locally supported basis functions' even make sense in the scalar bits?
      -what space does the superadj live in?
        -in full-field space...superadj components don't live in same space as aux var components...will need to change localization writeup, maybe procedure as well...wait no you don't...
        
=============================================================================

-vikram will look into 'continuation in operator space' idea
  -> see if karen knows anything about this? 
    -not that she knows yet
-couldn't find good reaction non-dimensionalization that didn't assume a particular ideal reactor or first-order reaction...but reaction coeff doesn't seem unreasonable for general second-order reactions?
-plotting error distribution?
  -isovolumes? only shows parts of domain within a set range, but hard to see how things would change within that range...
  -what would we want to show? qoi and which observations are important? series of isovolumes? to see at what point particular observations pop up? do we want that much detail?
-weird sign difference and timing of iterations-until-the-end...
-how should background/lit review differ from thesis'?
  -briefer than thesis...lit review shouldn't be its own section...should be part of intro, context of what the problem is and what you're doing and what's been done
*** -> 1.1 + 1.2 in thesis, pretty much what's in the thesis, can be briefer in motivation...single introduction section...
  -poke cube book?

-distribution -> can you scale z axis to make it more obviously 3D?
  -or stack of slices?
-estimate vs actual error, actual relative-to-HF error (in %age)
  -should rel error for stopping in algorithm? be relative to estimated HF qoi? or just describe algorithm in terms of some error-related tolerance?
    -> if it makes more sense to do error relative to estimated HF qoi as stopping criterion, will need to update graphs in 2D also...
***how much time does just inverse problem take at each iteration? if  you decided to use fresh data, even though breakdown not exact
  -should all have same (LF?) initial guess

==========

invMF debug: inv_MF -> psi_and_superadj phys module, inv_MF2 -> inv_HF_cont phys module (stabilization bits commented out)
-divvy1.exo -> initial resid agree (psiLF -> r=0, aniso)
  -do the end qois match? (577585 vs 577588 (577585 after porosity fix)) (was 577581 in psi_and_superadj...inv_MF and psi_and_superadj should only have differed in initial guess...)
  -wait are they even using the same initial guess?
    (LF norm: 100175.2947750192 vs 100175.29477501918)
    (Computed QoI is 1064697.829690268 vs 1064697.829690268)
    
--definitely looks like the HF inv problem shouldn't take nearly as long as we thought...you just got really unlucky with your jac check...
  -what if higher r term? have about 3 more orders of mag before it becomes unrealistic for general 2nd order reaction...
    -r=0 init guess
      -r=4.2e-3 (r in specialized code): well that stalled after a long-ass while...
        -with some continuation (still stalled...)
        -more continuation? (...the heck?)
        -even more continuation...
        -omigod this is so delicate wtf...
          -rerunning with jac check...checked out with 1.e-6 until death by newton, also manual check looks fine...
          -...also check that init residuals are diff for diff continuations? yes they are...
        -loosening to previous defaults (only init tol and max iter specified, same as previous defaults) doesn't seem to help
        -still running for 3.5e03 with even tinier steps...
          IS THERE A REINIT MISSING? reinit was just in case the variables hadn't been defined right? checking in run2 to see if repeating a step registers correctly...although before, the weird 616 showed up when manually doing continuation in splitpsi, not later in automated version...
            -repeating a step does show up correctly...
            -is the inverse problem for large nonlinearity just ill-defined? but newton's should still find some sort of local extrema?
        -> ****can tiptoe up to 3.22e-3...that takes 1900...well, 3.22 doesn't converge, but 3.21 does, and without any continuation (not even from LF)...seems that the ones it can get to, it can get to without any continuation...and the ones it can't get to, no amount of continuation will work...****
          -not requiring that residual be reduced at each step cauches r=3.22 to spin off into infinite residual...which apparently is not a failure...
      -r=1e-3 (r in specialized code): 790 (755 in linear); qoi: 377326.74286693614
      -adapt 0.05, 0.03 step fails newton at MF02
        -smaller r? 
          -1e-3, psi_and_superadj3
          -3.5e-3, psi_and_superadj3, fails at MF03 (<1% at end of MF02, 3700)
            -0.03 step, fails at MF05; goes to 0.6% of error, but kinks up to 7% at end...(dies at 23% refinement, last successful at 18% ref)
              -final estimated HF qoi: 213215
            -0.02 step, goes fairly smoothly to 0.6% error, then dies...(dies at 29% refinement, last successful at 26% ref)
              -final estimated HF qoi: 213008
        -what if LF also had aniso? (psi_and_superadj4; 0.03 step, still fails in MF03)
          -with looser tol? (psi_and_superadj4, still dies on MF03)
          -different steps?
            -0.1 (psi_and_superadj4, failed at MF01)
            -0.01 (psi_and_superadj4, dafuq this also failed at MF01? definitely different areas refined than 0.1...)
            -0.05 (psi_and_superadj4, failed at MF01)
            -0.05, r=3.5e-3 (psi_and_superadj4, failed at MF01)
      -what if loosened lin tols? (psi_and_superadj4/loose, still fails at MF03)
        -what was the 2D r=1000 doing? wasn't there the weird creeping to 616 thing?
          -r=1000 had tight tols, gmres; superlu also works fine
      -what if data was from reaction too?
        3.5? can't seem to get it for the inverse, but does the forward work at least? or does the inv break because there's no fwd steady-state?
          -fwd has twice the domain in length and width, and non-diri BCs though
            -running 3.5 with diri west, takes > 100 nonlinear steps...so maybe it really is quite nonlinear...initially 
          -adapt with 0.03 step and react-data fails in the adjoint solve?? wtf? that's linear how can it fail?
      -what if change steps in adaptive? (so not all same size...somewhere between 0.03 and 0.02?)
  -what if non-diri west c BC?
    -with LF init guess (165 (155 in linear), qoi = 1053771); doesn't converge (maybe forward ill-posed? but has react term...ksp residual norm suddenly spikes to e38, max/min ends at e14))
    -with r=0 init guess (126 (116 in linear), qoi = 1026703); seems stuck in linear solve...thousands of iterations...
    -with west-diri, r=0 init guess, converges in 520 (500 in linear), qoi = 547359
    -NEED TO REDO WITH bug fixed in west BC...uses previous assumption that "velocity" didn't include porosity...
    
    
what if you use reinit anyways?
white if write out and read in?
loose tol and not-require-resid-reduction together?
  or superlu and not-req...
  
  R = 0.003214 -> failed at finest steps thus far; previous step solves w/o continuation...
  run2 - does 0.003212 solve w/o continuation?

9245 - HF finest cont, gmres, no resid red required (inv_HF_halved_shifted_cont_psi_and_superadj_phys)
  -R = 0.003214 hit max NL iterations, R = 0.003215 spins off into infinity...
8090 - HF finest cont, superlu, resid red required (inv_HF_halved_shifted_cont_psi_and_superadj_phys)
  -died at R = 0.003214
8802 - HF rough cont, gmres, no resid red required (run2_psi_and_superadj_phys)
  -hit max NL iter on 3.225, went to 3.5, hit jacobian disagreement (max abs diff O(e-6), max rel diff O(e-7)); residual started increasing wildly beforehand...??
9887 - HF finer cont, gmres, no resid red required, tolerances like adj ex 2 (run2_psi_and_superadj_phys)
  -hit max NL iter on 3.225 and 3.25, went to 3.3, hit jacobian disagreement; residual started increasing wildly beforehand...??
11131 - HF finest cont, gmres, no resid red required, numerical jac (inv_HF_halved_shifted_cont_psi_and_superadj_phys)
 -died at R = 0.003214 ...analytical jacobian is very likely correct, stop worrying about it...
11863 - even more fine, original 4.2 (compare final qoi) (run2_psi_and_superadj_phys)
  -converged fine, ended at same qoi as original (to at least 9 sig figs)
12414 - even more fine, 3.5, gently from 0 (inv_HF_halved_shifted_cont_psi_and_superadj_phys)
  -still couldn't make it to 3.3...
11893 - even more fine, 3.5, gently from 0 (inv_HF_halved_shifted_cont_psi_and_superadj_phys)
  -failed at R = 0.0032136, same with vikram's (who used even gentler steps from 0)

-> try with inverse crime data points?
  -swift decay -> diri edge stands out starkly; also, source is cut by truncated domain...
    -original domain, flux BCs -> still has stark edge...really swift decay..perhaps it just doesn't make sense to have 'ambient/at-infinity' concentration of 5 anymore given this amount of reaction...west edge is supposed to represent what comes for upstream, where there is no source...
      -if set bsource = 0, then no edge ridge...most of action focused around source...very close for diri0...(requires zero initial guess to converge)
      
  -> move source to be within halved domain? enforcing incorrect flux or diri on edge that cuts through true source may also make things funky...although most sensors are fairly well away from edge...
 
-combustor example? what if it actually does drop reaction term? even if it doesn't make sense to do LF everywhere, it might make sense to use it *somewhere*...
  -if LF were no-reaction, it would just be conv-diff in the areas where it's used...
-adaptivity as offline? one-off solve with mixed faster than all-HF? POKE ARGUMENT IN CHAD'S PAPER
  -can we present this as more robust? 
-ask youseff if it makes sense to have multiple-vs-single reaction example? does it make sense to know/infer this particular set of parameters? stop by his office? maybe bart?
  -wait, can't you not have a variable exist in only parts of the domain? even if we do it the identity-jacobian way, is that the correct interpretation? would the MF model have pockets of zero concentration for extra species? or would the extra species exist but not react? second one makes more physical sense, but then you wouldn't have one model have more dofs than the other...
   -infer for reaction coeff, qoi = avg outlet temp? it's okay to have a scalar param...just that here, the LF inv prob would take no time cuz param would be determined completely by regularization...can still present LF inv problem as (linear? what about temp?) KKT, to get corresponding states...might the HF problem be more nonlinear because of the exponent?
  
  dual motivation? robustness and time savings?
  FD jacobian -> should converge to quadratically versus step size...clean up jacobian and let vikram look over?
  
!! inv with R = O(e7) and matching data doesn't converge from LF...
  -but then adaptivity, even with zero diri west bc, also has trouble converge MF01 with step 0.03...
  
future: time-depedent? all the cool stuff seems transient...terminal_output_nvel_realqoi_pe1_n0p1_3p5e8_adapt_em10tol_0p03step.txt
  
think about:
sergio's thesis -> chapter on weighting for importance sampling when you don't have a pdf, just samples; in high-dim, doing density optimation is an ass; solve weights as optimization problem
  -should've been published in statistics journal
  
-- maybe rather than think of large overarching topics, start from a little problem and let it grow?
  -this might not work well to stay on the photonics project...
  -apply to inverse problems? relation to filters? optimization instead of resampling?


karen update:
-example with high reaction (possible robustness example)
  -adaptivity gets to <1% estimated error, but HF won't converge so we can't compare accuracy
  -jacobian was fine, trying different solver tolerances didn't help
  -looks like difficulty in convergence was due to non-physical-looking boundary condition (not as pronounced for lower reaction..)
  -increasing reaction several orders of mag still did not require continuation past solving the LF inv prob first...
-steady-state combustion also looks too simple, not likely to give NL solver trouble...
-transience will probably be a big leap implementation-wise...idea seems simple, but debugging-wise...
  -can't just solve KKT system in one go, would need to either write a wrapper around libmesh or go to another library...
  
  makes more sense to just submit it and let them come back with comments if they have a problem...
  more columns/subtable: time to get the model, time to solve its inverse problem, time to get its error estimate
    -even if given an MF, it takes more time to solve the inv and get its error estimate than to solve the HF
    -what if HF and LF on different grids? keep HF on finer grid (so no additional disc error), but maybe the given-MF solve+error will be less than HF inv?
    -> send karen as soon as you get the results
  talk to omar next? see if he has suggestions?
  
*do explicit passing of c and auxc points...will not do to have reproducibility be so difficult in the future...
  0.05 step running
generate data from k with larger chunks of heterogeneity
test adding grad-k to regularization
  -even with less peaky k, still get almost linear p
  -smoothness of k does not prevent p from being non-linear; seems that inferred k has too-small range of magnitudes
poke diff-mesh lf-hf

would we be saving the superadj from the offline and not recomputing?

diff-mesh ...HF needs to do the HF mesh repeatedly, so even if superadj needs HF mesh too, it's only linear...
  diff vs conv-diff-react? (so no stability limit on coarseness of LF)
  back project fine error breakdown onto coarse, then find which coarse elements to refine
  -> poke adjoint_refinement_estimator.C? that seems to be about neighboring elements rather than nodes
    -split HF basis blame equally among all LF bases that overlap its support
  -if need more dof difference, can go back to 60-6-0.6, full domain

checking if high-R inverse also doesn't take much longer...(we'd only really checked for fwd)

inv_HF appears to be not full rank? lack of BCs on k?
  -J_p_ lines seem to be a lot smaller in magnitude that the others...would non-dimensionalization help? rank is approximately 2/3 of matrix size plus 2 sides and 3 data points...
    -> writing p in terms of MPa instead of Pa just scales the whole equation...same for writing k in darcies...scale BCs / average?
    
karen's idea: rerun case, timing all the individual pieces
  -just LF iteration (inv + err est) takes longer than HF problem...fewer fine mesh linear solves, but each one takes more gmres iterations...
  -in practice, adjoint is not usually at refinement at level of ultimate model (would have to be infinite dim...)...usually one additional refinement iteration is used...do the same for our superadjoint?
    -make sure nx/ny/nz ratios are the same and are factors of 2
    -see mesh_test for how to remove/allow buffers between h and h/4 elements (allowing buffer might make things easier to solve due to smoothness, but includes more dofs...)
    
    
--------------------    
    
    
check on detailed-time runs
  -running in psi_and_superadj - should also update qois and err est for point-pass
  
  -original 2:1 timing breakdown
    -compare timing of single iteration (inv + aux + sadj) compare to HF?
      -HF: 85991.739688138085 (830)
      -LF: 170632.22587129171
      -running in _v2: 5458
  
  -original R, 32x64x32 HF, 4:1
    -3D version: LF mesh too coarse to register qoi 1 (LF = 8x16x8)
      -using qoi0
        -first refinement fraction is less than the refinement step...?!? not seen in 2D version...
          -> you confused break and continue...
      -qoi2
        -0.01 step: slightly more time to finish LF+MF01 than HF...fwd in MF01 takes more than superadj...
        -0.005 step: slightly less time to finish LF+MF01 than HF...estimated relative error is small, but way off...
  -original R, 64x128 HF, 4:1
    -qoi2: HF qoi = 6834.3800652242126 (15 to solve for)
        -0.005 step: 
  
  what if you need to refine an element that was previously partially refined as a buffer?
    -even with no buffers, multi-level not working; see gdb output in dbg.txt on bassi
#0  libMesh::MeshRefinement::test_level_one (this=0x7fffffffc950, libmesh_assert_pass=true) at src/mesh/mesh_refinement.C:410
#1  0x00007ffff5e2f3fe in libMesh::MeshRefinement::coarsen_elements (this=0x7fffffffc950) at src/mesh/mesh_refinement.C:605
#2  0x00007ffff615cec2 in libMesh::EquationSystems::reinit (this=0x7fffffffd3f0) at src/systems/equation_systems.C:239
#3  0x00000000004dde72 in main (argc=10, argv=0x7fffffffe408) at main.C:696
  (dies at second call to refine_elements when creating MF01; setting breakdpoint at MeshRefinement::face_level_mismatch_limit() shows no calls but what we explicitly call, so not sure how _face_level_mismatch_limit becomes 1 when we set it to 0 in the beginning...)
  -> what's max_h_level for? can you refine twice in one call? or is that only for uniform refinement?
  -> reinit calls coarsen_elements, which, according to its documentation, must satisfy the level-one rule...still not sure how the _face_level_mismatch_limit is being changed, but if we constrain refinement to the level-one rule, than reinit seems fine...
      -> setting use_buffer_zone to true makes it stop complaining about the second reinit...maybe reinit is bugged/designed so that it doesn't work with all levels of hanging nodes?
        -> reinit creates its own MeshRefinement object, just for the function call...need to recompile libmesh to work with it...
    
  MF01 fwd seems much more fragile than same-mesh cd vs cdr; need to take itty-bitty steps...
    -> put LF and HF both to HF mesh, see if it's the physics or node mismatch?
      -> worked out fine to end of MF02 (0.03 step)
    -> is there some extra housekeeping during mesh refinement?
      -> it should work if diff vs convdiff, cuz then linear...if this works, then some weird interaction between reaction and mesh...or missing housekeeping didn't break easier problem...
        -> MF01 ran fine...(0.03 step)
      -> misc ex4 uses refine_elements instead of refine_and_coarsen_elements ; only thing different from our code is that every element is explicitly flagged (as inactive, to-refine, or do-nothing...)
        -> on 3x3x3 test, the 2beef8, 7546df, and 71e45c versions all give the same init resid for primary in MF01...all do the same when h_LF/h_HF=2
    -> what if loosen linear tol?
      -doesn't seem to help; LF aux solve keeps failing...
    -> output intermediate psi's on the meshes they were solved on?
      -> pre_proj.exo
    -> projection-on-reinit seems to be working fine (divvy vs pre-proj)
    -> for 0.03 step up to 4.2e-5 works fine, but not 4.2e-4 or 4.2e-3
    -> oddly, using 'flat' data meant for 2D works fine for 4.2e-4 in 3D (and 2D)

  MF01 appears less sensitive in 2D...debug do everything in 2D first, before bumping up to 3D for pictures?
    -if you let it refine indefinitely, at some point it stops refining...??
    -refining completely in one go doesn't give zero estimated error ??
      -for 8x8x8 same-mesh, superlu, fully-refined gives effectively no error
      -for 8x8x8 diff-mesh, superlu, fully-refined gives enormous error...not sure if due to large (absolute) residuals due to coarseness...
      -for 16x32x16 diff-mesh
        -primary solve for MF01 also almost 0...very sketchy...LF solved fine though...
      -for 16x32 diff-mesh, ridiculous estimated error (appears to mostly be from aux solve, which has large absolute residual, but stops because of rel step size tol...)
        -primary solve for MF01 also almost 0...very sketchy...LF solved fine though...
        -if no continuation, then primary solve for MF01 is completely 0...
        -> when you refine the mesh, you no longer know which element the data points belong in... (8/3/16)
          -> 16x32x16 case - gets below 5% tol in one step (MF01 solves fully, successfully)
          -> 16x32 case - all iterations solved fine
            -> if LF = 4x8, with 4x ratio, compiled against tweaked libmesh with EquationSystems patch is fine with or without buffer
    -very coarse aux sadj is dying via newton even with superlu...??
    -wtf the linear inv LF doesn't even solve in one step with superlu...??
      -gmres and superlu end up in the same place, at least in terms of QoI: 84387911.200470656 vs 84387911.200470656
      -pre diff-mesh code also has that; see inv_HF_halved_shifted_cont_psi_and_superadj_phys/terminal_output_nvel_realqoi_pe1_n0p1_3p5em2_jacfix2_sofinerer_superlu2.txt
      -> is there something wrong with superlu?
      -pc_type lu -pc_factor_mat_solver_package superlu -pc_factor_nonzeros_along_diagonal
      -ksp_type preonly -pc_type lu -pc_factor_mat_solver_package superlu
          -> neither gets the linear solves in one go, but the one on top doesn't seem seem to solve to residual 0...and yet doesn't break the 8x8x8 tests?
          
split indicator vs error?
  -sadj on HF mesh when want to estimate error, on slightly coarser mesh when just want to find places to refine?
    -> do 2D case with much larger diff between HF and LF meshes? you can totally do finer mesh than bare minimum for not-need-stability...
maybe there's just something about the mixed systems that makes the linear solves harder somehow? like how helmholtz/maxwells doesn't play nice with gmres? maybe the "pc_type ilu" makes a difference in the timing in how much it costs? play with different flags?
  11702 - repeating a 2:1 run with different flags
  11628 - timing if refined in one go? is the effect of initial guess so great?
    -what if you do same-mesh, make LF aniso and with velocity? and refine in one go, direct transfer option off? then timing should be similar...
      -12317 in v1 (MAKE SURE TO UNDO CHANGE IN CONVDIFF_PRIMARY AFTERWARDS)
        -wtf not even first R=0 solve matches...initial residual is same, but then krylov iterations are not...
          -same for R=4.2e-4 (same residual, then krylov iterations differ...)
            -> adapt HF replication was run without ilu precond... -> terminal_output_dbg_10itermax.txt ; if same flags, then lin iters look the same, but then the residuals start diverging...
              -in 2D things are exactly the same...in 3D (8x8x8) with 2D data, starts diverging...tkdiff shows no noticeable differences...
                -matches when updated to new libmesh
        -diff vs cdr forgets to make U=0 along boundaries when touching LF subdomain...eh they all do...

--------------------------------
        
-ksp_monitor_singular_value -ksp_gmres_modifiedgramschmidt -ksp_gmres_restart 500 -pc_type ilu -pc_factor_levels 4 -pc_factor_shift_type nonzero

-pc_type lu -pc_factor_mat_solver_package superlu -pc_factor_nonzeros_along_diagonal (
-ksp_type preonly -pc_type lu -pc_factor_mat_solver_package superlu (this one uses superlu as a precond, and applies only precond)
    
do we really need sadj to be at least as fine as MF mesh? wasn't the point of having regular adjoint on slightly finer mesh so that it wouldn't give 0 when weighted with residual? but here our highest ideal is the HF mesh, so in areas where the MF mesh is refined up to HF, we can't/don't need the adj to give nonzero weight with residual...
  -> no not really...
  
do a run where you use the final MF (and maybe its aux and superadj) on new data and time? vs HF?

interpretations:
-adaptivity is faster than doing HF inv
  -> our HF inv's are too easy
-online-offline - use adaptivity to choose MF that you then solve inverse problem with once data arrives
  -> do you calculate aux and/or superadj with new data or use ones saved from adaptivity?
    -LF and HF on same mesh
      -table 3: single MF iteration (MF + error estimate) sometimes faster than HF inv, but sometimes slower
    -LF and HF on diff meshes (x2 difference)
      -MF inv problems sometimes take longer than HF inv problem...even with significantly fewer DOFs...
        -vikram inquiring list as to whether such mixed models should have a different linear solver...maybe gmres is not appropriate somehow?
        -try a version with similar HF setup (and bcs, and data) as in paper? (can't, qoi region too small to show up on coarse mesh...)
    -LF and HF on diff meshes (x4 difference, superadj on x2 (more error, but probably closer to what would happen in practice?))
      -letting 0.03 step, with buffer, qoi2 run for a while in _v2 -> has trouble solving MF02 inv...
      -terminal_output_4p2em4_adapt_0p05step_0p05tol_flat_HF4x_sadj2x_buffer.txt: -> has trouble solving MF01 inv...
      -2D, HF128x256 : you get all the way to 100% refinement and the estimated relative qoi error stays 30+...ridiculous estimated HF qoi all the way...does adj resid need to stay finer than mixed? 
        -shouldn't the weighted residual still go to zero at 100% refinement, regardless of where sadj is (as long as it's in a subspace of HF)?
        -> evaluate residuals on HF (project psi and superadj)? projecting psi down to coarser areas messes up orthogonality
          -rerun: now 100% refinement gives no error, and estimated relative qoi error stays reasonable...
        -doesn't take much %HF for MF mesh nodes to exceed sadj mesh nodes (~20%)
        -when linearizing sadj about primary and aux, if primary and aux are projected down to coarser (in some parts) sadj mesh, then some info is lost...so even more error, but this time due to implementation...each EquationSystems is built from one mesh and it doesn't seem possible to communicate with systems in other EquationSystems objects...
          -inv and aux seems to have hard time solving...many more GMRES iters and much more overall solve time than HF...
            -what if strong pc flags?
              -funny, for once not all the runs take less time...now has inv timing increasing with %HF...
              -if only count solve time, then can finish up to MF02 (inv and error est) while staying less than HF inv solve time (~28 vs 30); has <1% relative error (true and estimated) by end of MF02
                -times for projections are considerable relative to solve times...probably only in 2D?
              -what if greater h_LF/h_HF ratio, no buffer? **
            -what if LF diff also aniso?
              -with strong pc flags, doesn't make much of a difference
        -running in 3D with fixed weighted residual - terminal_output_4p2em4_adapt_0p05step_1em10tol_sadj2x_HF4x_buffer_qoi2.txt
          -MF01 inv dies in newton...
          -0.03 step also dies
            -not requiring residual reduction doesn't help...
            -anisoLF running in v2 (aniso strongest in z-direction, so maybe heterogeneity is too much in 3D?)
              -MF01 and MF02 solve, but take ridiculously long...
              -if done with weakpc flags, then inv won't solve for even LF iteration...death by newton, hits max linear iters...
              -what about strong pc flags, no cont? nope MF01 still takes ridiculously long to solve
        
      we have:
      -single iteration may or may not take longer than HF inv; have cases where MF inv consistently takes less time than HF inv
        -coarsening LF mesh doesn't seem to help (either inv takes more time to solve, or reduction is insufficient (superadj still takes too long, HF problem probably insufficiently nonlinear to keep searching in this direction))
        -having superadj be on coarser mesh than HF introduces additional error
          -seems to be much less accurate (possibly theory needs tweaking...)
          -MF inv seems to have more trouble solving...
      if we stop inquiring to into the diff-mesh line, is table 3 adequate? or do we need to do comparison where final (or all?) MFs and HF get the same initial guess? (technically aux and superadj are linear and so shouldn't depend on init guess for convergence, but it might change the number of linear iters...) if so, do we need to use different data?
      
    -> replace scalar vs field with a 3D x2 case? (both show reduction of DOFs)
      
v1: checking that one step to HF matches invHF...it does in terms of iteration output...and also timing (850 vs 860)...so at least the inverse module and solver options match...is there something about mesh refinement that leaves dofs from previous iterations lying around? is there some housekeeping we've been forgetting that doesn't show up in EquationSystems::n_dofs()?
  -> refining all in one step could potentially expose shenanigans? 
    -2D HF64x128: 1-step total of LF+HF inverse problems < invHF (19 vs 30, superlu)
      -if actually do adaptivity, then none of the inverse probs take longer either... (MF01 and MF02, superlu and gmres)...is there something wrong with refinement in 3D? looks like 2D can also have problems in x4 case...
      
------------------------------------      
      
      
-x2 cases:
  *how does jac for MF compare to HF? Is it more dense/ill-conditioned/etc? Where is gmres sensitive?
  *what do the KSP residuals look like? Cost per ksp iter? What occurs at each iter?
  *can you import MF01 jac to matlab?
  *what happens if you refine just one node's blame?       
  -first solve MF's given same init guess...see if weirdly large time still occurs...
    -MF01 has different initial residual than during adaptivity, even though both have LF solution as init guess...(init resid 592 vs 676)
      -LF qoi matches...MF01 QoI doesn't quite match...in same-mesh case, QoI's agreed to 5+ sig figs...  
      -error estimates are way off...
        -looks like there was a bug in variable transfer of psi to mprime system?
          -error estimates more reasonable now, but still not what they were before...
      -zero init guess - should still be able to solve primary correctly...and thus all the other vars...
        -compared with adaptive run with no continuation...init resid is same for MF01, but jacobian seems different, cuz ksp residual starts out different...(*** WTF?? ***)
        -no difference in any of the physics modules (only difference is extra solveInit if-else, but even when that's commented out), same run flags, same data
          -calling for update of data locations and reinit() makes no difference
        -> perhaps, in the way that the mesh written to exo keeps no inactive elements, the adapted and read-in systems have their DOFs in a different order (so jacobian has swapped rows and columns) and that affects how the preconditioner performs...in HF case, the much better match is perhaps due to the meshes being formed the same way (LF, then refine all, then reinit)...
          -swapping order of z and f (order of add_variable call) changes init KSP residual very slightly...
          -test by print out matrices in 2D, see if they're permutations of one another?
            -wait now init resids aren't agreeing (wait which ones?)...1-step and HF init resids match to 12 sig figs, but init KSP resid deviates...
              -compare the eep.mat in diff_mesh/inv_MF and diff_mesh/psi_and_superadj_libmesh_1_0_0 -> matlab on athena?
                -they appear to be permutations of each other (same sums and sum of absolutes; also found moved rows (ex: 20 appears swapped with one of 56, 83, 116, 137, 164)), though their relative difference in condition number is O(e-7)
                -moving around more rows/columns changes the condition number more
      -inv timing increases with dofs, but now HF timing more than the rest...
        terminal_output_divvy1_diridata.txt:Time for inverse problem: 536.240093 seconds...
        terminal_output_divvy2_diridata.txt:Time for inverse problem: 804.75221299999998 seconds...
        terminal_output_divvy3_diridata.txt:Time for inverse problem: 979.02992500000005 seconds...
        terminal_output_HF_diridata.txt:Time for inverse problem: 2153.7936540000001 seconds...
          ->** can we just start at LF and let this represent a situation where you don't have a 'better' init guess for HF?
          -> try R=0 init? init resid agree (vs HF R=0), and KSP residuals are very similar (to 8+ sig figs, though not the same...)
            -init residuals and KSP residuals for subsequent HF run match to 8+ sig figs; total timing similar to inv_HF run
            -divvy1 QoI with LF and R0 init guess match, but don't match adaptive (169877 vs 169877 vs 170370)
              -same for divvy2 and divvy3; not HF though...R0-start HF QoI agree in both implementations, but not with LF-start HF, which happens to be the one that took much longer than usual...since physics modules are copied, maybe it really is dependent on init guess?
                -final residuals both O(e-11), though LF-start's is slightly smaller (3e-11 vs 5e-11)
                -1-step adaptivity (equivalent to LF init guess) has same residual when starting HF iteration (to 10+ sig figs), but KSP residuals start out slightly different and diverged from there...run without required residual reduction took ridiculously long and was cut off after 15+ hours; rerunning with required residual reduction correctly had no effect on first linear solve, but also took forever to converge (was cut off)
                -1-step adaptivity replication of HF_inv, even when using project_solution instead of DirectTransfer, matches inv_HF to every printed digit...something about refinement?
                  -using uniformly_refine instead of marking each element and calling refine_elements doesn't change anything
                  -if in the inv_MF code you make LF mesh, read LF solution into it, refine the mesh to HF and reinit, then the KSP iter changes to be much closer to adaptivity's (match to 10+ sig figs at first, stays closely matched until KSP residual gets really small)
            -discrepancy must be related to mixed mesh?
              -read in meshes have no inactive elems...does that mean inactive elems were just not written to divvy exo, or that they lost their inactive flag? -> inactive elems not written (compare n_elem with number calculated based on %refined)
              -subdomains preserved...or at least, the existence of different subdomains...
            -inv timing increases with dofs, but now HF is only slower than MF01...
              terminal_output_divvy1_diridata_R0start.txt:Time for inverse problem: 416.748131 seconds...
              terminal_output_divvy2_diridata_R0start.txt:Time for inverse problem: 685.40955099999996 seconds...
              terminal_output_divvy3_diridata_R0start.txt:Time for inverse problem: 843.15726299999994 seconds...
              terminal_output_HF_diridata_R0start.txt:Time for inverse problem: 508.199724 seconds...
    -what if you remove modifiedgramschmidt (heavier duty option) and fewer pc_factor_levels? try on same-mesh case first?
      -> v2: 24157 wow that really changed the times...now inv time no longer increases monotonically (MF02 < HF < MF01 < MF03)
      -> v2: 28555 running with old flags again while signed off...was there something else running the first time or other thing that interferred with timing? nope, times remain mostly unchanged...wow that's weird...
      -> v2: 31501 - even less pc (pc_factor_levels 1)
      -> v2: 31775 - same as above, but with no continuation...MF01 took a ridiculously long time with pc_factor_levels 1
    -if it really seems like it's not a bug and just a funny coincidence, then try for 4x?
does it die during coarse LF run? yes...wtf? fails at convdiff_mprime.C:93 commenting out calls to get_xyz in init_context seems to fix things...??

-table 3, MF02 (and MF03) are weird...why the blip? is it possibly related to why the x2 case is weird? is there something about the mixing that screws up conditioning/sparsity/other nice properties?
  -slivers of one between the other? maybe we need to enforce some sort of blobiness...
  -> run inv_MF with table 3's divvys - is the blip still there? (or weird coincidence of init guess?
    -blip is still there; time/KSP iter doesn't seem to make sense, especially for HF...is assembly after each linear iter hurting HF unfairly? HF has fewest total linear iters, but second-largest time...calls to assemble() only take <10 seconds (out of 350 total) in HF though...
    -inverse jacobian sparsity pattern is only affected by where R is nonzero (J_c_c, the others are shared...) ...is this responsible for HF's large time/KSP iter? but time/KSP iter doesn't increase with % refinement...
    -MF02 blip has both more linear iters and more time per iter...
    -what exactly does gmres do?
      -at iteration n, you solve (n+1)x(n) linear problem...
      -monitor_singular_value flag: Prints the two norm of the true residual and estimation of the extreme singular values of the preconditioned problem at each iteration
      -Like other iterative methods, GMRES is usually combined with a preconditioning method in order to speed up convergence. The cost of the iterations grow as O(n2), where n is the iteration number. Therefore, the method is sometimes restarted after a number, say k, of iterations, with xk as initial guess. 
    -if you allow just one iteration (so no unfairness from different assemble calls), then all the MF's have very similar numberof KSP iters in frst NL solve, decreasing slightly with more refinement; HF still has, like, 20% of the KSP iters, but takes almost exactly the same amount of time
      -different time spent in preconditioning? turning off preconditioning (pc_type none) causes ridiculously slow convergence (LF, MF01, HF; no convergence after 1000 gmres iters...) ...
      -MF02's KSP iter blip doesn't show until third linear solve
      -cost of each iteration is supposed to be as O(n^2), so what if you cut off linear iters? and have no precond? does time seem to scale appropriately then?
        -if no precond and capped at 100 linear iters, LF and MF01 and HF take the same amount of time (similarly for cap at 400)
    -difference in time vs KSP iterations appears to be from preconditioning...so why is preconditioning weirdly difficult for MF02 somewhere in the middle of its NL iters?
    -using alternate data (generated using very different BCs and domain) seems to give more reasonable timing (generally slowly increases with % refinement) but qoi error (estimated and actual) is crazy in the middle...
      -MF02 blip doesn't appear to be property of mesh? appears to be funny coincidence with data...
      -tightening linear solver tolerances didn't help with err est craziness, so not likely due to aux/sadj being insufficiently resolved...
      -from MF02 to MF04, the QoI got further from the HF QoI, so maybe it so happened that for these the psiMF was very different from the psiHF...?

-reverse same-mesh case? do inverse-crime data first, then different data?
  -what if you did the adaptivity on Table 5's data? how sensitive is the adaptivity to the actual data value?
    -adapt on Table 5's data (diri0), then give it new weird data?
      -> MF02 inverse fails newton ...for both 0.03 and 0.05 steps...
    -(adapt with shifted, solve inv with diri5) vs (adapt with diri5, solve inv with shifted)
      -adapted with shifted seems to do well with diri5 data...error estimate stays reasonable, true error generally decreasing (though slowly...actual relative error goes from 4% to 2% between MF01 and MF06...)
        -adapt with diri5 for diri5 data does slightly better for each %HF...but even LF error starts small (5%), so LF qoi vs HF qoi were not so different to begin with...R=0 qoi error is much larger (20%)
      -adapted with diri5 gets super lucky at MF02 (very small actual error, though much larger estimated error), though afterwards error decreases and error estimate gets better (not as good as when adapted-for-diri5 used for diri0, but seems to be about as good as adapted-for-shifted used for shifted)
      -adapted-with-shifted probably less spastic when used with diri5 data than diri0 data cuz shifted data done with diri5 BCs and probably the half-dom...so closer to diri5 data...
    -(adapt with shifted, solve inv with diri0) vs (adapt with diri5, solve inv with diri0)
      -adapt with shifted takes until MF05 (37% HF) to get reasonable error est (MF01 happened to do well, but then went crazy with MF02-MF04)
      -adapt with diri5 has hiccup at MF02 (in actual and estimated error), but error starts trending down afterwards (and error estimate reasonable starting at MF03 (25% HF))
    -> in general, there is no guarantee that error (true or estimated) decreases as %HF increases
    -> adapting for a dataset tends to give the best error reduction per %HF when solving MF inv probs with that dataset (which makes sense...)
    -> since it seems that having the dataset used for adaption be closer to the dataset used for inference gives better error reduction per %HF, it's best to do adaptivity using expected data (having weird (not-similar-to-models) data in either adaptivity or when doing inference seems to make for worse results...)
  -what happens if you do weaker precond on the same-mesh? is that making the weird MF02 hiccup?
    -seems to generally make things faster, though doesn't change the ordering of timing (things that took the most time still take the most time)
    -timing might still be related to condition number; didn't see much condition number difference at first NL iteration, but might diverge more later...not sure how to check later condition numbers though...
  -if it continues to have time blips, what happens if you avoid refining boundary? something screwy at boundary? or alternatively, keep everything on boundary at HF?
    -if you avoid refining boundary elements, then starting at MF07, where %HF=36.8%, the MF inv problems take significantly longer than HF inv problem...perhaps do to something like a 'boundary layer' between the HF and LF parts...
  -is it necessarily true that a greater %HF should take more time? what about in the stokes-NS paper? did they even do timing?
    -stokes-NS only notes that mixed problems converged in a few Newton iterations to a small residual; no comparison between different mixtures
    -does it make more sense to think of greater nonlinearity as requiring more nonlinear steps? instead of increasing the difficulty of intermediate linear solves?
  -what if you started with LF instead of R=0? (since LF includes isotropy in diff)
    -more refined ones take longer than with R=0 init guess, but then later refinements and HF come very close together in inv timing
  -what if MF didn't have inhomogeneity in diff?)
    -does anisotropy even show up in the jacobian like it would for FD? the dphi*D*dphi becomes a single number? it must show up somehow if it's able to mess with stability...
  -> tell karen the results, even if they don't show anything...
  
-if we can fix the 1:2 with LF init guess, might have a case for HF > adapt
  -what if you do 1-step with uniform refinement? if that works, then you missed some housekeeping...
    -> 2993 nope that didn't change anything...
    
    -breaking apart iterations with diff init guess is unfair...what if two refinements are "closer", like smaller continuation step?
    
-----------------------------------
 
-same mesh cases
  -any adaptivity iteration takes longer than HF inv, but given MF models and same initial guess, solving MF-inv takes less time (more if error estimate needed)
    -inv timing does not increase monotonically with %HF given same initial guess
      -should it?
      -# NL iters increases monotonically (not strictly) with %HF given same initial guess
-diff mesh cases
  -1:2
    -MF<HF, using same data as from adaptivity, but...
      -LF-init-MF01 timings/KSP iters do not agree between adaptivity code and inv_MF code
      -QoIs don't agree between adaptivity codes and inv_MF codes
        -since LF-init and R0-init HF QoIs also disagree, possible that the different initial guesses led to different local minima, though not in LF-init-MF01 case...
        -since doing HF by making the mesh straight-out vs using uniform refinement changes the KSP iters, possible that nothing is wrong, and during adaptivity the DOFs are arranged differently and that changes the timing/KSP iters...
      -in inv_MF code, HF takes a lot longer only if LF-init, not if R0-init
  -1:2:4 LF:sadj:HF
    -ridiculous error estimates; error estimates don't become zero at full-refinement, possible incorrect implementation of weighted residuals (wrong meshes)
    	-> fixed


Aug 23 16:09 - pointpush -> you forgot to clear cvals after each iteration...error estimates and such are probably off...
  -pre-fix data stashes in pink
  -terminal_output_4p2em4_adapt_0p05step_1em10tol_sadj2x_HF4x_buffer_HF128x256_qoi2_weakpc.txt : difference is almost imperceptible
  
--------------------------------------------------
8/25

-same-mesh
  -almost inv-crime data (except with finer mesh) + normal noise (zero mean, 0.05 stddev), 10 datasets; adaptivity done with inverse crime data
  	-increasing %HF does not necessarily reduce QoI error (true and estimated) even during adaptivity, although kinks appear confined to first few iterations...so far...
  	-given same initial guess, increasing %HF does not necessarily increase the time (although it seems to never decrease the number of NL iters); HF inv still consistently takes the longest
-1:2:2
  -can make post-process argument, but only if HF starts at LF not R=0...LF is perhaps a more general initial guess? since in our case there so happens to be more linear aspects in the HF model compared to LF model, but that's not true in general?
  	-> yes
-1:2:4
  -2D case where doing adaptivity takes less time than HF (if only counting solve time, since projection time is significant in comparison)
  	-projection is necessary though, so you can't really count it out...
  -3D case current having solver trouble (isoLF) or weird timing (anisoLF)
  	-maybe we just mention the possibility in the conclusion, rather than fill with too many tricks?
  
-table 6: why is it even possible for increasing %HF to mess up the QoI so bad?
	-are there little pockets of elements? because of discontinuous flux, maybe HF islands are not really HF? check if there are pockets? (1 basis fx's worth) **
	-is MF02 worse + takes more time because of pockets? doesn't look like it has exceptional amount of pockets...
-only adapt/inv with HF+finer+noise?
	-you do this on the assumption that your HF model is correct...what are you doing with such wrong data? (note this in conclusion? we recommend not doing this method if HF not trusted)
-replace 5 and 6 with noisy set

-> strip out nonsense-adapted tables, make it clearer

-what do you want the examples to show?
	-2D convdiff vs cdr
		-simple setup, easy to see progression of error estimate and breakdown
		-vs QoI, vs data location - interpretation of error breakdown
	-2D scalar vs field
		-different kinds of models that can be mixed; MF model can also have reduced DoFs in addition to reduced nonlinearity
		-alternatively : 3D diff-mesh, 1:2
			-done with almost-inv-crime (diff BC) data
			-QoI error estimate terrible at LF and MF01
			-just-inv timing much better than HF when all started at LF
	-3D convdiff vs cdr
		-more "realistic" baseline; adapt using almost-inv-crime, solve online inv probs using noisy data; MF inv faster than HF inv, MF models continue to perform well with noisy data
			-this also assumes that you guessed the inferred parameters correctly, though, in generating the data...
-> if use multiple 3D examples, should keep BCs consistent between them...
	-redo 3D 1:2 with diri5 and inv-crime data for adaptivity (RUNNING in v1), maybe also run with set of noisy data?
		-init residual with LF init not matching between inv_MF and adaptive ; MF01 inv won't even solve with same data...
			-rerunning adapt with printout of refined elems...rebuild refined meshse in inv_MF code, see if that makes a difference? what if you also solve invLF, reinit, refine mesh...? **
				-written in diff_mesh/inv_MF, not yet run
