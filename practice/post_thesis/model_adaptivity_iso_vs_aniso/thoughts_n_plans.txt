-> inverse prob for LF and HF; to avoid optimization algorithm, solve KKT system
  -> which adjoint system? stabilized adjoint or transposed of stabilized jacobian? for optimization problem where we care about a particular discretization, we want to use the transpose of the stabilized forward as the adjoint...
  -> is the adjoint of the stabilized system even the stabilized adjoint-of-unstabilized?
    -what is the meaning of the adjoint of a stabilized system anyways? the stabilization depends on the discretization...
      -> see supg_analysis.pdf
  -> what does the adaptivity theory rely on?
  
...aren't we inferring for a smooth source term, so regular stabilization should be fine?

debug:
nan residual?? after the linear solve...c doesn't seem to have moved from initial guess, based on qoi...also numerical and analytical jacobians don't match
  -> checking analytical jacobians takes a long time...on 46x33x3 mesh, two jacobians now match...still get nan...
  -> 5x5x3 should be small enough for matlab to read in without freezing...
    -nan whether supg toggled on or off
    -J is not full rank...311/432...fwd J was full rank, so shouldn't be about BCs of fwd+adjoint...
      -> if we view z as a forcing for f, then the gradient equation doesn't have a unique solution? is the regularization insufficient to make the problem well posed cuz it penalizes the gradient? is that why you chose forcing to be zero at boundaries?
      -> if f given homo Diri BCs, then J still not full rank (422/432) (485/504 for 5x6x3 mesh...)
      -> does giving either of the other BCs diri BCs fill up the remaining rank deficit?
        -f and c have homo diri: 352/432 O.o??
        -f and z have homo diri: 311/432
        -something wrong in interior? if all have homo diri and side residual contribution set to zero, still get nan's
          -interior terms look the same as in old cd_all inverse system...
          -matlab says rank is 417/432; if velocity increased to 2.415 (remove e-5 factor), then matlab thinks it's full rank...scaling problem? even with inceased velocity, still get nan...
          -do not get nan if superlu used with regular velocity, but then qoi becomes negative...same for original non-Diri BCs...
            -superlu is not the way to go...on 92x66x5 mesh, even bassi chokes...doesn't finish after 30 minutes...
          -if using inputs for HF for long_channel_stash/qoi2_setup02/HF, recover recorded QoI using superlu, but also get nan residual using default solver; Jacobian on coarser mesh is full rank
          
    system    mesh    variation                             gmres           gmres w/shift           superlu       rank(J)       cond(J)
    nandbg    25x5                                    fails, resid e7                               resid e-17    468/468 **      e3
    nandbg    15x3                                    resid e-14                                    resid e-17    192/192 **      e3
    invLF     5x5x3   f homo diri, no supg            fails, resid nan                              resid e-10    422/432 (same with fixed beta/gradf signs)
    invLF     5x5x3   f homo diri, vel*e5, no supg    fails, resid nan                              resid e-9     429/432
    invLF     5x5x3   f homo diri, vel*e6, no supg    fails, resid nan                              inex newt fails, resid e-8)         
    invLF     46x33x3  f homo diri, vel*e6, no supg                         inex newt fails, (resid e-1) resid e-9
    invLF     46x33x3  f homo diri, vel*e6, no supg, disp 400               inex newt fails, (resid e-2) resid e-8
    invLF     46x33x3  f homo diri, vel*e6, no supg, disp 4000              inex newt fails
    invLF     5x5x3   all homo diri, no supg          fails, resid nan                              resid e-7     417/432
    invLF     5x5x3   all homo diri, vel*e5, no supg  fails, resid nan                              resid e-7     432/432 **      e11
    invLF     5x5x3   all homo diri, vel*e6, no supg                        resid e-1 (9 order reduction)         432/432 **      e9
    invLF     5x5x3   all homo diri, vel*e6, #4 supg                        resid e-2 (10 order reduction)        432/432 **      e9
    invLF     46x33x3  all homo diri, vel*e6, no supg                       resid e-4 (11 order reduction)        
    invLF     5x5x3   all homo diri, vel*e5, no supg, disp 400              resid e-2 (10 order reduction)        432/432 **      e9
    invLF     5x5x3   all homo diri, vel*e5, #4 supg, disp 400              resid e-1 (9 order reduction)         432/432 **      e9
    invLF     5x5x3   all homo diri, vel/decade, no supg, disp 400          resid e-2 (9 order reduction)         432/432 **      e12
    invLF     5x5x3   all homo diri, option 4 supg    fails, resid nan                              resid e-7     417/432  
    invLF     5x5x3   f homo diri, option 4 supg      fails, resid nan                              resid e-9     422/432 
    nandbg    5x5x3   all homo diri, no supg          fails, resid nan                              resid e-7     417/432
    fwd       5x5x3   iso 40                          resid e-7                                     resid e-10    144/144 **      e2  
    nandbg    25x5x5  gave data z-coord, else same    fails, resid nan      resid e-9               resid e-16    TOO LARGE TO READ INTO MATLAB
    nandbg    15x3x3  gave data z-coord, else same    fails, resid nan      resid e-11              resid e-15    768/768 **      e3
    nandbg    15x3x3  gave data z-coord, just f diri                        resid e-12                            768/768 **      e6
    nandbg    15x3x3  gave data z-coord, just f diri, const v=0.5           resid e-11                           
    
    -nondimensionalize, compare current nandebug (put old nandbg params into invLF code?)?
      --wouldn't change the peclet number...is that what's really at the heart of f-homo-diri cases skimming singularity?
      -first implement last nandbg in inv_LF
        -sign on beta*grad_c and cpred-cstar were inconsistent...if match nandbg, then recover same qoi..if flip signs, then newton solve fails...
      -how to nondimensionalize with tensor diff? do you also scale domain?
        -without scaling domain, dividing by tensor*disp -> current nondimensionalization messes up 15x3x3 nandbg qoi...(should be 1.05191)
    -or maybe you really do need to go parallel?
    
    -> add pc_factor_shift_type nonzero:
    ./progname -ksp_monitor_singular_value -ksp_gmres_modifiedgramschmidt -ksp_gmres_restart 500 -pc_type ilu -pc_factor_levels 4 -pc_factor_shift_type nonzero
      -> singularity of J perhaps related to velocity term being too small relative to element size? maybe forward and adjoint, which only differ by sign of velocity, look too similar? no, one acts on adjoint and one acts on state...different columns...
        -> only velocity and reaction use time...
      -> on bassi
          92x66x3
            iso, all homo diri - almost 3 hours of "alive time", but only 6 minutes of "active time"...
            iso, f homo diri - 8.3 hours of "active time", but about 12.2 hours of "alive time"...
            iso, no diri
            aniso, f homo diri
            aniso, no diri
          184x132x4
            iso, f homo diri
            iso, no diri
            aniso, f homo diri
            aniso, no diri
        
bart told karen he has an example that would be applicable to master's and easy to apply in milo?
--> focus on getting the two papers written and submitted this semester before opening more cans...will help you narrow down your ideas and see what work can/should still be done...and to understand what it means to have something finished...you should be expecting to get 2-3 papers from thesis...

karen will be at mit 4/6-7

date for forming committee is a guideline...

----------------------------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------------------------

DO NOT EVER USE HARD RESET EVER AGAIN IT DOESN'T JUST APPLY TO SUBDIRECTORIES IT APPLIES TO THE WHOLE REPO

----------------------------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------------------------

bart didn't seem to have any actual model pairs in mind, just ideas for applications...batteries? also using summer cd(r)...

-if we want to compare linear solves, then need to make sure that linear solves are being solved precisely (especially with iterative solvers!)
-sometimes a newton solve with not converge if linear solves done precisely, but sometimes the looseness of inexact solve can save it (ex: continuation on HF cdr, 600->700 doesn't work if superlu used...)

-write up new error breakdown
  -RUN NEW ERROR BREAKDOWN WITH SCALAR VS FIELD
-ask if continuationsystem can be used for the desired purpose
  -yes, but arclength continuation is overkill...natural continuation is more common...calculating optimal parameter stepsizes would require tangent information of some sort, and at that point you might as well use arclength...which is meant for robustness, not necessarily for efficieny...
-streamline psi-to-superadj
  -how long does it take to set up meshes/system objects? if significant, is there a way to just reassign subdomain IDs? have all the divvy text available and read them in? (re-run from start-to-finish each time new divvy available)
  -reassign subdomain ID without changing current solution? keep that as initial guess?
  -seems like it might be lot less work to read in xda files like in superadj than to read in exo like in psi_MF...psi_MF had a lot of time spent in inverse_map() under FE...
    -is psi_MF also reads in psiLF_mesh.xda instead of exo mesh, time spent in inverse_map() doesn't change...
    -inverse_map() is called in relation to sensor points...not sure why called ten times more often in psiMF than superadj...
      -order of mag difference doesn't appear in psiLF iteration with R=-42...both spend considerable time there...
      -number of calls reduced to about 1/3 if only 1 of 3 datapoints kept, and yet if explicit calls counted, they only amount to hundreds, not millions...majority of explict call count also disappears if no numerical vs analytical jacobian comparison...
      -contains_point calls inverse_map...and you're calling that for every element...use PointLocatorTree to find and store element that points are in...
  -solution transfer hopefully doesn't take up too much? (nope it doesn't)
  -is it fair to not count refinement in timing? just cuz you're doing it in matlab...which is probably not the most efficient way either...
    -if we have a problem where the two methods are sufficiently different, it shouldn't matter...
  -can we make a basis function a vector of original basis functions? would that help with grouping basis functions by node?
    *****what if you just trust that every group of 6 belongs to the same node?*****
  
  -LF iteration, superlu: 
    split codes = 25+72=97 (10+51=61 in linear solve)
    joined code = 90 (63 in linear solve)
    joined code, split super-adj = 50 (20 in linear solve)

  -FOR FINAL COMPARISON:
    -turn off numerical jacobian check
    -turn off norm checks
    -use analytic velocity for both
    -be consistent with solver tolerances
    -close other programs...what's playing on youtube affects runtime...
    
-benjamin model thoughts:
  -combustion
  -stokes v navierstokes
  -ROM for LF? how to stitch? if a LF/MF linear solve is cheaper, than all the better...but how fares the theory?
  -time dependent oscillations - reactor tube or flow over clamped wing
  
  -> first try with scalar A, E? what about just inferring k, and not the parameters that describe it based on the Arrhenius eq?
  -> alternative to arrhenius equation? ("of Arrhenius type and modeled as in Cuenot and Poinsot")
    -alternatives to even having concentrations to powers? (vikram will look at this)
  -> field vs scalar E? hopefully field E makes things nonlinear enough to require many more nonlinear steps...
    -does it even make sense to make E a field?
    -what happened to previous attempts to limit scalar and field param variables to different subdomains?
      -see practice/T_channel/diff_param_res/all_linear/get_psi_MF_discon/debug_notes.txt:
  -> HF: couple non-newtonian flow? depends on temp...what sorts of reactants would this make sense for?
  -> HF: couple to compressible navier stokes? (density depends on temperature; varying density would also affect reaction expression)
  -> Galagali, Nikhil: thesis on different combustion models...
    -seems to be about inferring (stochastically) for intermediate reaction mechanisms (infer for pathway) and their reaction rates
  -> Rebecca Morrison: might have some knowledge of chemical model hierarchies
    -> nikhil and rebecca are both youseff's...maybe ask him?
  -> just make the LF a ROM? gah how to those work?
    -need HF fwd runs in order to build basis...that would probably have to be included in the cost of even creating LF model...
    -projection-based: let the solution only exist in subspace of R^n, defined by a not-full-rank basis; would affect state and adjoint, but not params...ROMs for inverse problems?
    -each component of the reduced basis is likely to have nonzero components inside and/or outside the LF regions...do we just ignore those bits that are outside the LF regions? pretend they were just given?
    -doesn't seem easily implementable in libmesh...though it does have a 'Reduced Basis' section in examples...
    -can theoretically still use a ROM, but will probably need specialized method to build the basis...
  -can we/would it make sense to infer temp from measurements of temp?
  -HF has additional reactions that also affect temperature? (instead of adding intermediate reactants, just have other species with their own reactions that also contribute to temp...)
    -ex: 2H_2 + O_2 -> 2H_2O, C + O_2 -> CO_2; C is a contaminant? (also N2+O2=2NO, 2NO+O2=2NO2)
      -if LF is assuming C = 0 (no carbon-oxygen reaction), then MF model will have 'pinning' in LF parts of domain...can have pinned value in initial guess?
    -pure-oxygen vs "air"? combust methane in oxygen vs in air?
    -impure mixture doesn't even need to be air...make up some contaminant...
      -NOx has complicated mechanism, and doesn't seem to have a simple version with O_2 instead of O
      -kinda weird, though, to know the params for your contaminants but not your main reaction...
  -if you knew the field for H_2 and O_2 and T, could you write equation for H_2O as convdiff with reaction term as source? infer for parameter describing inlet H_2 and O_2 (and inlet T?) and also parameterizing fields (say, you guess it'll look somewhat half-eliptic?), which thus parameterizes forcing?; measurements of H_2O or T?
    -if parameters can be used to create analytical expressions for H_2, O_2, T fields, couldn't you make this a ROM? basis depending on analytical expression, not derived from original FE basis functions?
    -parameters that affect diri BCs...how to derive adjoint, and is that something you could implement?
    -what if you do H_2 and O_2 fields without reaction, and read them in to create forcing function? based on assumption that H_2 and O_2 concentrations large enough so as to be mostly unaffected by reaction? 
      -if there is a shat ton more of one reactant than another, then the amount of product is limited by the availability of the scarcer species...can't quite divorce the product from the concentration of *both* reactants though...
    
-stokes vs navierstokes
  -parameters in b+v are actually not in diri bcs...would appear in weak form...
  -does it really not make sense to try to mesh stokes and navierstokes in one domain? at least, not have large parts of domain with the very different reynolds numbers...
-different physics + different mesh resolutions? HF: more nonlinear and higher resolution?
  -vikram poking whether libmesh can do this...-> yes
  
-does having localized reaction (as if other reactant(s) were available at only certain location, and which concentration was very large/kept constant; or as if catalyst sufficiently reduced activation energy only in some region) make the problem more nonlinear?
  -cdr solve, r = 400, centered at (2.5,0.5)
    -everywhere: 5 NL iters
    -r exponetially decaying, decay param 1:  5 NL iters
    -r exponetially decaying, decay param 10: 4 NL iters
    -r exponetially decaying, decay param 20: 4 NL iters
    -r exponetially decaying, decay param 20: 3 NL iters
  -it shouldn't...otherwise MF with cd+cdr would be worse...
    
  -what happens to the qoi if you remove data points altogether? (in chad's thing, there seemed to be the possibility of certain data points being ignored/not of much weight) how does the error breakdown change? what if you change the data values?
    -can we use this to say something about experimental design?
    -adjoints are about sensitivity to perturbations...sadj_auxc seems to indicate most sensitivty to data mismatch near middle sensor...?
      -sensitivity of what? error in qoi?
        -kinda seems to fit that interpretation...if you could only have one sensor in one of the three positions, then having middle gives lowest relative difference in QoI...if you had a right sensor and could only add middle or left sensor, then most reduction in relative difference in QoI if add middle...same if you had left sensor at first...relative difference increases from just-right to left+right, so is this even a good measure?
        
        
poke dissolution/precipitation forward problem, see if it does have an interesting steady state?
  -if not, then try **iso conv-diff vs aniso conv-diff-react**? or **inferring for k with regular cd vs cdr**?
  -try inexact-linear-solve continuation on original problem, vs newly integrated? does newly integrated benefit from loose linear solve?

is continuation not 'state of the art' enough because we would not normally even solve the whole KKT system, and instead go for optimization program? harder to compare the two then...although even for optimization a good initial guess is sometimes needed...

natural continuation vs integrated adaptivity: (strict linear solve, gmres)
  r = 0 inv: 4.5 (3 in linear)
  r = -442: cont steps (0,100,200,300,400,442) < adaptive (1 step, 0.11 final fraction) < cont steps (400, 442)
    -> 25 (15 linear ) vs 35 (23 linear) vs 40 (28 linear)
    -> 1 adaptive step, 0.11 final refinement fraction, 0.0144 estimated relative error, 0.0035 actual relative error
  r = -1000: adaptive < cont steps (0:100:1000) < cont steps (400:100:1000) < cont steps (0,400:100:1000)
    -> 43 (30 linear) vs 56 (35 linear) vs 67 (45 linear) vs 96 (72 linear)
    -> 1 adaptive step, 0.11 final refinement fraction, 0.0115 estimated relative error, 0.004 actual relative error
    -> this looks possibly promising...**do 3D version with iso conv-diff vs aniso conv-diff-react?** (same mesh first?)
      -ONLY RUN 3D ON BASSI

3D iso conv-diff vs aniso conv-diff-react
  -halve each dimension and origin-align? can do parallel for inv and fwd, but will make adaptivity more difficult (deal with elements across processors)
  -LF inv in serial with strict linear tol and 92x66x20 mesh takes 3+ hours (get stuck at e-10 residual for some reason...solves on 5x5x5, weird glitch in ssh?)
  -inv, quartered domain, 46x33x20, n=0.3
    -iso 100: 155 (141 in linear)
    -iso 40: 160 (147 in linear)
    -aniso 100-40-4: 220 (200 in linear)
    -aniso 100-40-4, r = +1e-3: 466 (433 in linear)
    -aniso 100-40-4, r = +2e-3: freaking forever
    -aniso 100-40-4, r = (0,e-3,1.5e-3,2e-3): 3392 (3140 in linear)
    -aniso 100-40-4, r = (0,e-3,1.5e-3,2e-3), v = nv: 21798 (20336 in linear; seems to have hit max NL iter?)
  -inv, quartered domain, 25x45x30, no stabilization (n in vel), n=0.3
    -iso 100: 160 (150 in linear)
    -iso 40: 158 (150 in linear)
    -aniso 100-40-4, r = (0,e-3,1.5e-3,2e-3), v = nv: 1117 (1043 in linear)
    -aniso 100-40-4, r = (0,1,1.5,2,2.5,3,3.5,4.2)e-3, v = nv: 2480 (2300 in linear); qoi: 547209.61
  -inv, quartered domain, 25x45x30, no stabilization (n in vel), n=0.1
    -iso 100, r=0: 159 (151 in linear); qoi = 1068855.6709150125
      error estimate vs 4.2e-3: -333214.34175340564
      error estimate vs 4.2e-4: -400936.34636102663
    -aniso 100-40-4, r = (0,1,1.5,2,2.5,3,3.5,4.2)e-3: 2470 (2300 in linear); qoi = 547417.81514302175
THERE WAS A BUG IN THE JACOBIAN OF HF CONTINUATION (REACTION TERM)
    -aniso 100-40-4, r = (0,1,1.5,2,2.5,3,3.5,4.2)e-3, jac-fix: 
      12135 (11724 in linear); qoi = 547420.85898380179
      (wow we must've gotten really lucky before with the wrong jacobian...)
    -aniso 100-40-4, r = (0,1,1.25,1.5,1.75,2,2.25,2.5,2.75,3,3.25,3.5,3.75,4,4.2)e-3
      22040 (21290 in linear); qoi = 547422.15360160533
    -aniso 100-40-4, r = (0,1,2,3,4.2)e-3, jac-fix: 
      7432 (7170 in linear); qoi = 547421.62359722063
    -aniso 100-40-4, r = (0,2,4.2)e-3, jac-fix: 
      6587 (6446 in linear); qoi = 547421.59753930464
    -aniso 100-40-4, r = (0,4.2)e-3, jac-fix:  
      6210 (6130 in linear); qoi = 547419.95996741741
THERE WAS ANOTHER BUG IN THE JACOBIAN OF HF CONTINUATION (REACTION TERM)...even though previous one passed jac check...
    -aniso 100-40-4, r = (0,4.2)e-3, jac-fix:  
      350 (330 in linear); qoi = 547417.92230248486
    -adaptive: (r = 4.2e-4), 0.1 steps
      MF01: qoi = 577581.79809296422; estimated rel error = -0.038311485179517969; actual relative error = -0.0522
        Final refinement fraction: 0.16651851851851851; if stop here, 1113 (1035 in linear)
        just inv, psiLF start: 338 (322 in linear); just inv, r=0 start: 317 (301 in linear)
      MF02: qoi = 548904.34911934205; estimated rel error = 0.002185847354112873; actual relative error = -0.002718
        Final refinement fraction: 0.29025185185185187; if stop here, 1795 (1672 in linear)
        just inv, psiLF start: 389 (374 in linear); just inv, r=0 start: 390 (374 in linear)
      MF03: qoi = 547773.23232645926; estimated rel error = 0.00032135133846412049; actual relative error = -0.000644
        Final refinement fraction: 0.42269629629629629; if stop here, 2222 (2050 in linear)
        just inv, psiLF start: 248 (232 in linear); just inv, r=0 start: 246 (230 in linear)
    -adaptive: (r = 4.2e-4), 0.05 steps (psi_and_superadj2)
      MF01: qoi = 613418.65290589374; estimated rel error = -0.066492866621420899; actual rel error = -0.1075915977
        Final refinement fraction: 0.0927; if stop here, 1040
        just inv, psiLF start: 267 (251 in linear); just inv, r=0 start: 265 (250 in linear)
      MF02: qoi = 558522.85455398832; estimated rel error = 0.002080804223470499; actual rel error = -0.019877534
        Final refinement fraction: 0.169; if stop here, 1864
        just inv, psiLF start: 402 (387 in linear); just inv, r=0 start: 393 (377 in linear)
      MF03: qoi = 550323.00719542312; estimated rel error = 0.0045611526719650146; actual rel error = -0.0052751566
        Final refinement fraction: 0.237; if stop here, 2417
        just inv, psiLF start: 266 (250 in linear); just inv, r=0 start: 251 (236 in linear)
      MF04: qoi = 548224.52965272486; estimated rel error = 0.0030239362458373475; actual rel error = -0.0014675915
        Final refinement fraction: 0.304; if stop here, 2965
        just inv, psiLF start: 328 (312 in linear); just inv, r=0 start: 344 (328 in linear)
      MF05: qoi = 547743.82753993955; estimated rel error = 0.0011951462532848933; actual rel error = -0.0005912756
        Final refinement fraction: 0.372; if stop here, 3309
        just inv, psiLF start: 248 (233 in linear); just inv, r=0 start: 247 (231 in linear)
      MF06: qoi = 547531.83860096941; estimated rel error = 0.00035427666447780811; actual rel error = -0.0002043327
        Final refinement fraction: 0.446; if stop here, 3642
        just inv, psiLF start: 246 (230 in linear); just inv, r=0 start: 287 (269 in linear)
  
THE LAST TWO REFINEMENTS HAVE THE WRONG SIGN...WAS THERE SOMETHING TWITCHY ABOUT OUTPUTTING c_points and aux_c points to file? weird seg fault during first run, if no such files already in directory...?
AAAHHH ADAPTIVITY WAS DONE WITH REACTION 4.2e-4, while continution was 4.2e-3...
  -> not a typo...one of the codes includes porosity in reaction term, the other doesn't...e-4 is with multiplication by porosity...
  
  is there a good way to show 3d error dist? error seems most concentrated near qoi region, makes everything else almost invisible...
====================================================================================
-from last time...
  -integrated adaptivity steps into one time-able code
  -model from benjamin - haven't come up with reasonable LF or HF model to go with it
  -continuation
    -natural continuation - more steps sometimes faster; can try a bunch of step sizes and pick best? or look for heuristics?
    -arclength continuation - seems to be commonly used in NL FEM solvers, but 'overkill' if no bifurcation; more about robustness than efficiency
  -3D porous media, combinantion of monty and nicer (but still in range of what's seen in porous media) alphas
  
-meaning of r? is there a non-dimensional version of r? either have units or non-dimensionalize? damenkoler number?
  -can you justify r?
-try a few more continuation sequences
-table of times and errors? (MF01, MF02, MF03)
-reactive turbulent combustion - turbulence is hard, as is the shat tons of intermediate reactions...
  -refinement of graphs? poke manishika about graph theory?
  
  http://chemwiki.ucdavis.edu/Core/Physical_Chemistry/Kinetics/Methods_of_Determining_Reaction_Order#Second-Order_Reactions
  p.683 of 'remediation of hazardous waste contaminated soils' by donald l. wise (scan of chapter requested from iliad)
  'Evaluation of the kinetic oxidation of aqueous volatile organic compounds by permanganate' 
    -total second order (two reactants); rate constants are O(e-8) at most...perhaps because aqueous and chemwiki reactions were gaseous?
  
  hmm...do you know anyone who might be able to help with the Damkohler number question? the expression on wikipedia is the most general I can find, but I don't know what the diffusive/convective 'mass transport rate' is in our equation...the reaction rate is change in concentration per time, so it has units [M/L^3/T] (Mass-Length-Time), but I'm not sure what in the convection-diffusion aspects of our equation has those units...the more specific reactions on the wiki page, as well as the other expressions I've found, seem to be derived for particular reactors and reaction orders (most assume first-order reactions, or particular idealized reactors)...
  
mind maps?
====================================================================================
  
field vs scalar error plots need colorbar readjusted to show more than just spastic fringes...
    -wow those fringes are really spastic...can we fix them? are they the source of the spaz in the error?
      -f and auxf aren't really oscillating at the fringes though..well pinned...
      -are the basis functions for blaming even done properly? at the boundaries, they would only be half a hat...
      -does the idea of 'locally supported basis functions' even make sense in the scalar bits?
      -what space does the superadj live in?
        -in full-field space...superadj components don't live in same space as aux var components...will need to change localization writeup, maybe procedure as well...wait no you don't...
        
=============================================================================

-vikram will look into 'continuation in operator space' idea
  -> see if karen knows anything about this? 
    -not that she knows yet
-couldn't find good reaction non-dimensionalization that didn't assume a particular ideal reactor or first-order reaction...but reaction coeff doesn't seem unreasonable for general second-order reactions?
-plotting error distribution?
  -isovolumes? only shows parts of domain within a set range, but hard to see how things would change within that range...
  -what would we want to show? qoi and which observations are important? series of isovolumes? to see at what point particular observations pop up? do we want that much detail?
-weird sign difference and timing of iterations-until-the-end...
-how should background/lit review differ from thesis'?
  -briefer than thesis...lit review shouldn't be its own section...should be part of intro, context of what the problem is and what you're doing and what's been done
*** -> 1.1 + 1.2 in thesis, pretty much what's in the thesis, can be briefer in motivation...single introduction section...
  -poke cube book?

-distribution -> can you scale z axis to make it more obviously 3D?
  -or stack of slices?
-estimate vs actual error, actual relative-to-HF error (in %age)
  -should rel error for stopping in algorithm? be relative to estimated HF qoi? or just describe algorithm in terms of some error-related tolerance?
    -> if it makes more sense to do error relative to estimated HF qoi as stopping criterion, will need to update graphs in 2D also...
***how much time does just inverse problem take at each iteration? if  you decided to use fresh data, even though breakdown not exact
  -should all have same (LF?) initial guess

==========

invMF debug: inv_MF -> psi_and_superadj phys module, inv_MF2 -> inv_HF_cont phys module (stabilization bits commented out)
-divvy1.exo -> initial resid agree (psiLF -> r=0, aniso)
  -do the end qois match? (577585 vs 577588 (577585 after porosity fix)) (was 577581 in psi_and_superadj...inv_MF and psi_and_superadj should only have differed in initial guess...)
  -wait are they even using the same initial guess?
    (LF norm: 100175.2947750192 vs 100175.29477501918)
    (Computed QoI is 1064697.829690268 vs 1064697.829690268)
    
--definitely looks like the HF inv problem shouldn't take nearly as long as we thought...you just got really unlucky with your jac check...
  -what if higher r term? have about 3 more orders of mag before it becomes unrealistic for general 2nd order reaction...
    -r=0 init guess
      -r=4.2e-3 (r in specialized code): well that stalled after a long-ass while...
        -with some continuation (still stalled...)
        -more continuation? (...the heck?)
        -even more continuation...
        -omigod this is so delicate wtf...
          -rerunning with jac check...checked out with 1.e-6 until death by newton, also manual check looks fine...
          -...also check that init residuals are diff for diff continuations? yes they are...
        -loosening to previous defaults (only init tol and max iter specified, same as previous defaults) doesn't seem to help
        -still running for 3.5e03 with even tinier steps...
          IS THERE A REINIT MISSING? reinit was just in case the variables hadn't been defined right? checking in run2 to see if repeating a step registers correctly...although before, the weird 616 showed up when manually doing continuation in splitpsi, not later in automated version...
            -repeating a step does show up correctly...
            -is the inverse problem for large nonlinearity just ill-defined? but newton's should still find some sort of local extrema?
        -> ****can tiptoe up to 3.22e-3...that takes 1900...well, 3.22 doesn't converge, but 3.21 does, and without any continuation (not even from LF)...seems that the ones it can get to, it can get to without any continuation...and the ones it can't get to, no amount of continuation will work...****
          -not requiring that residual be reduced at each step cauches r=3.22 to spin off into infinite residual...which apparently is not a failure...
      -r=1e-3 (r in specialized code): 790 (755 in linear); qoi: 377326.74286693614
      -adapt 0.05, 0.03 step fails newton at MF02
        -smaller r? 
          -1e-3, psi_and_superadj3
          -3.5e-3, psi_and_superadj3, fails at MF03 (<1% at end of MF02, 3700)
            -0.03 step, fails at MF05; goes to 0.6% of error, but kinks up to 7% at end...(dies at 23% refinement, last successful at 18% ref)
              -final estimated HF qoi: 213215
            -0.02 step, goes fairly smoothly to 0.6% error, then dies...(dies at 29% refinement, last successful at 26% ref)
              -final estimated HF qoi: 213008
        -what if LF also had aniso? (psi_and_superadj4; 0.03 step, still fails in MF03)
          -with looser tol? (psi_and_superadj4, still dies on MF03)
          -different steps?
            -0.1 (psi_and_superadj4, failed at MF01)
            -0.01 (psi_and_superadj4, dafuq this also failed at MF01? definitely different areas refined than 0.1...)
            -0.05 (psi_and_superadj4, failed at MF01)
            -0.05, r=3.5e-3 (psi_and_superadj4, failed at MF01)
      -what if loosened lin tols? (psi_and_superadj4/loose, still fails at MF03)
        -what was the 2D r=1000 doing? wasn't there the weird creeping to 616 thing?
          -r=1000 had tight tols, gmres; superlu also works fine
      -what if data was from reaction too?
        3.5? can't seem to get it for the inverse, but does the forward work at least? or does the inv break because there's no fwd steady-state?
          -fwd has twice the domain in length and width, and non-diri BCs though
            -running 3.5 with diri west, takes > 100 nonlinear steps...so maybe it really is quite nonlinear...initially 
          -adapt with 0.03 step and react-data fails in the adjoint solve?? wtf? that's linear how can it fail?
      -what if change steps in adaptive? (so not all same size...somewhere between 0.03 and 0.02?)
  -what if non-diri west c BC?
    -with LF init guess (165 (155 in linear), qoi = 1053771); doesn't converge (maybe forward ill-posed? but has react term...ksp residual norm suddenly spikes to e38, max/min ends at e14))
    -with r=0 init guess (126 (116 in linear), qoi = 1026703); seems stuck in linear solve...thousands of iterations...
    -with west-diri, r=0 init guess, converges in 520 (500 in linear), qoi = 547359
    -NEED TO REDO WITH bug fixed in west BC...uses previous assumption that "velocity" didn't include porosity...
    
    
what if you use reinit anyways?
white if write out and read in?
loose tol and not-require-resid-reduction together?
  or superlu and not-req...
  
  R = 0.003214 -> failed at finest steps thus far; previous step solves w/o continuation...
  run2 - does 0.003212 solve w/o continuation?

9245 - HF finest cont, gmres, no resid red required (inv_HF_halved_shifted_cont_psi_and_superadj_phys)
  -R = 0.003214 hit max NL iterations, R = 0.003215 spins off into infinity...
8090 - HF finest cont, superlu, resid red required (inv_HF_halved_shifted_cont_psi_and_superadj_phys)
  -died at R = 0.003214
8802 - HF rough cont, gmres, no resid red required (run2_psi_and_superadj_phys)
  -hit max NL iter on 3.225, went to 3.5, hit jacobian disagreement (max abs diff O(e-6), max rel diff O(e-7)); residual started increasing wildly beforehand...??
9887 - HF finer cont, gmres, no resid red required, tolerances like adj ex 2 (run2_psi_and_superadj_phys)
  -hit max NL iter on 3.225 and 3.25, went to 3.3, hit jacobian disagreement; residual started increasing wildly beforehand...??
11131 - HF finest cont, gmres, no resid red required, numerical jac (inv_HF_halved_shifted_cont_psi_and_superadj_phys)
 -died at R = 0.003214 ...analytical jacobian is very likely correct, stop worrying about it...
11863 - even more fine, original 4.2 (compare final qoi) (run2_psi_and_superadj_phys)
  -converged fine, ended at same qoi as original (to at least 9 sig figs)
12414 - even more fine, 3.5, gently from 0 (inv_HF_halved_shifted_cont_psi_and_superadj_phys)
  -still couldn't make it to 3.3...
11893 - even more fine, 3.5, gently from 0 (inv_HF_halved_shifted_cont_psi_and_superadj_phys)
  -failed at R = 0.0032136, same with vikram's (who used even gentler steps from 0)

-> try with inverse crime data points?
  -swift decay -> diri edge stands out starkly; also, source is cut by truncated domain...
    -original domain, flux BCs -> still has stark edge...really swift decay..perhaps it just doesn't make sense to have 'ambient/at-infinity' concentration of 5 anymore given this amount of reaction...west edge is supposed to represent what comes for upstream, where there is no source...
      -if set bsource = 0, then no edge ridge...most of action focused around source...very close for diri0...(requires zero initial guess to converge)
      
  -> move source to be within halved domain? enforcing incorrect flux or diri on edge that cuts through true source may also make things funky...although most sensors are fairly well away from edge...
 
-combustor example? what if it actually does drop reaction term? even if it doesn't make sense to do LF everywhere, it might make sense to use it *somewhere*...
  -if LF were no-reaction, it would just be conv-diff in the areas where it's used...
-adaptivity as offline? one-off solve with mixed faster than all-HF? POKE ARGUMENT IN CHAD'S PAPER
  -can we present this as more robust? 
-ask youseff if it makes sense to have multiple-vs-single reaction example? does it make sense to know/infer this particular set of parameters? stop by his office? maybe bart?
  -wait, can't you not have a variable exist in only parts of the domain? even if we do it the identity-jacobian way, is that the correct interpretation? would the MF model have pockets of zero concentration for extra species? or would the extra species exist but not react? second one makes more physical sense, but then you wouldn't have one model have more dofs than the other...
   -infer for reaction coeff, qoi = avg outlet temp? it's okay to have a scalar param...just that here, the LF inv prob would take no time cuz param would be determined completely by regularization...can still present LF inv problem as (linear? what about temp?) KKT, to get corresponding states...might the HF problem be more nonlinear because of the exponent?
  
  dual motivation? robustness and time savings?
  FD jacobian -> should converge to quadratically versus step size...clean up jacobian and let vikram look over?
  
!! inv with R = O(e7) and matching data doesn't converge from LF...
  -but then adaptivity, even with zero diri west bc, also has trouble converge MF01 with step 0.03...
  
future: time-depedent? all the cool stuff seems transient...terminal_output_nvel_realqoi_pe1_n0p1_3p5e8_adapt_em10tol_0p03step.txt
  
think about:
sergio's thesis -> chapter on weighting for importance sampling when you don't have a pdf, just samples; in high-dim, doing density optimation is an ass; solve weights as optimization problem
  -should've been published in statistics journal
  
-- maybe rather than think of large overarching topics, start from a little problem and let it grow?
  -this might not work well to stay on the photonics project...
  -apply to inverse problems? relation to filters? optimization instead of resampling?


karen update:
-example with high reaction (possible robustness example)
  -adaptivity gets to <1% estimated error, but HF won't converge so we can't compare accuracy
  -jacobian was fine, trying different solver tolerances didn't help
  -looks like difficulty in convergence was due to non-physical-looking boundary condition (not as pronounced for lower reaction..)
  -increasing reaction several orders of mag still did not require continuation past solving the LF inv prob first...
-steady-state combustion also looks too simple, not likely to give NL solver trouble...
-transience will probably be a big leap implementation-wise...idea seems simple, but debugging-wise...
  -can't just solve KKT system in one go, would need to either write a wrapper around libmesh or go to another library...
  
  makes more sense to just submit it and let them come back with comments if they have a problem...
  more columns/subtable: time to get the model, time to solve its inverse problem, time to get its error estimate
    -even if given an MF, it takes more time to solve the inv and get its error estimate than to solve the HF
    -what if HF and LF on different grids? keep HF on finer grid (so no additional disc error), but maybe the given-MF solve+error will be less than HF inv?
    -> send karen as soon as you get the results
  talk to omar next? see if he has suggestions?
  
*do explicit passing of c and auxc points...will not do to have reproducibility be so difficult in the future...
  0.05 step running
generate data from k with larger chunks of heterogeneity
test adding grad-k to regularization
  -even with less peaky k, still get almost linear p
  -smoothness of k does not prevent p from being non-linear; seems that inferred k has too-small range of magnitudes
poke diff-mesh lf-hf

would we be saving the superadj from the offline and not recomputing?

diff-mesh ...HF needs to do the HF mesh repeatedly, so even if superadj needs HF mesh too, it's only linear...
  diff vs conv-diff-react? (so no stability limit on coarseness of LF)
  back project fine error breakdown onto coarse, then find which coarse elements to refine
  -> poke adjoint_refinement_estimator.C? that seems to be about neighboring elements rather than nodes
    -split HF basis blame equally among all LF bases that overlap its support
  -if need more dof difference, can go back to 60-6-0.6, full domain

checking if high-R inverse also doesn't take much longer...(we'd only really checked for fwd)

inv_HF appears to be not full rank? lack of BCs on k?
  -J_p_ lines seem to be a lot smaller in magnitude that the others...would non-dimensionalization help? rank is approximately 2/3 of matrix size plus 2 sides and 3 data points...
    -> writing p in terms of MPa instead of Pa just scales the whole equation...same for writing k in darcies...scale BCs / average?
    
karen's idea: rerun case, timing all the individual pieces
  -just LF iteration (inv + err est) takes longer than HF problem...fewer fine mesh linear solves, but each one takes more gmres iterations...
  -in practice, adjoint is not usually at refinement at level of ultimate model (would have to be infinite dim...)...usually one additional refinement iteration is used...do the same for our superadjoint?
    -make sure nx/ny/nz ratios are the same and are factors of 2
    -see mesh_test for how to remove/allow buffers between h and h/4 elements (allowing buffer might make things easier to solve due to smoothness, but includes more dofs...)
    
    
--------------------    
    
    
check on detailed-time runs
  -running in psi_and_superadj - should also update qois and err est for point-pass
  
  -original 2:1 timing breakdown
    -compare timing of single iteration (inv + aux + sadj) compare to HF?
      -HF: 85991.739688138085 (830)
      -LF: 170632.22587129171
      -running in _v2: 5458 **
  
  -original R, 32x64x32 HF, 4:1
    -3D version: LF mesh too coarse to register qoi 1 (LF = 8x16x8)
      -using qoi0
        -first refinement fraction is less than the refinement step...?!? not seen in 2D version...
          -> you confused break and continue...
      -qoi2
        -0.01 step: slightly more time to finish LF+MF01 than HF...fwd in MF01 takes more than superadj...
        -0.005 step: slightly less time to finish LF+MF01 than HF...estimated relative error is small, but way off...
  -original R, 64x128 HF, 4:1
    -qoi2: HF qoi = 6834.3800652242126 (15 to solve for)
        -0.005 step: 
  
  what if you need to refine an element that was previously partially refined as a buffer?
    -even with no buffers, multi-level not working; see gdb output in dbg.txt on bassi
#0  libMesh::MeshRefinement::test_level_one (this=0x7fffffffc950, libmesh_assert_pass=true) at src/mesh/mesh_refinement.C:410
#1  0x00007ffff5e2f3fe in libMesh::MeshRefinement::coarsen_elements (this=0x7fffffffc950) at src/mesh/mesh_refinement.C:605
#2  0x00007ffff615cec2 in libMesh::EquationSystems::reinit (this=0x7fffffffd3f0) at src/systems/equation_systems.C:239
#3  0x00000000004dde72 in main (argc=10, argv=0x7fffffffe408) at main.C:696
  (dies at second call to refine_elements when creating MF01; setting breakdpoint at MeshRefinement::face_level_mismatch_limit() shows no calls but what we explicitly call, so not sure how _face_level_mismatch_limit becomes 1 when we set it to 0 in the beginning...)
  -> what's max_h_level for? can you refine twice in one call? or is that only for uniform refinement?
  -> reinit calls coarsen_elements, which, according to its documentation, must satisfy the level-one rule...still not sure how the _face_level_mismatch_limit is being changed, but if we constrain refinement to the level-one rule, than reinit seems fine...
      -> setting use_buffer_zone to true makes it stop complaining about the second reinit...maybe reinit is bugged/designed so that it doesn't work with all levels of hanging nodes?
        -> reinit creates its own MeshRefinement object, just for the function call...need to recompile libmesh to work with it...
    
  MF01 fwd seems much more fragile than same-mesh cd vs cdr; need to take itty-bitty steps...
    -> put LF and HF both to HF mesh, see if it's the physics or node mismatch?
      -> worked out fine to end of MF02 (0.03 step)
    -> is there some extra housekeeping during mesh refinement?
      -> it should work if diff vs convdiff, cuz then linear...if this works, then some weird interaction between reaction and mesh...or missing housekeeping didn't break easier problem...
        -> MF01 ran fine...(0.03 step)
      -> misc ex4 uses refine_elements instead of refine_and_coarsen_elements ; only thing different from our code is that every element is explicitly flagged (as inactive, to-refine, or do-nothing...)
        -> on 3x3x3 test, the 2beef8, 7546df, and 71e45c versions all give the same init resid for primary in MF01...all do the same when h_LF/h_HF=2
    -> what if loosen linear tol?
      -doesn't seem to help; LF aux solve keeps failing...
    -> output intermediate psi's on the meshes they were solved on?
      -> pre_proj.exo
    -> projection-on-reinit seems to be working fine (divvy vs pre-proj)
    -> for 0.03 step up to 4.2e-5 works fine, but not 4.2e-4 or 4.2e-3
    -> oddly, using 'flat' data meant for 2D works fine for 4.2e-4 in 3D (and 2D)

  MF01 appears less sensitive in 2D...debug do everything in 2D first, before bumping up to 3D for pictures?
    -if you let it refine indefinitely, at some point it stops refining...??
    -refining completely in one go doesn't give zero estimated error ??
      -for 8x8x8 same-mesh, superlu, fully-refined gives effectively no error
      -for 8x8x8 diff-mesh, superlu, fully-refined gives enormous error...not sure if due to large (absolute) residuals due to coarseness...
      -for 16x32x16 diff-mesh
        -primary solve for MF01 also almost 0...very sketchy...LF solved fine though...
      -for 16x32 diff-mesh, ridiculous estimated error (appears to mostly be from aux solve, which has large absolute residual, but stops because of rel step size tol...)
        -primary solve for MF01 also almost 0...very sketchy...LF solved fine though...
        -if no continuation, then primary solve for MF01 is completely 0...
        -> when you refine the mesh, you no longer know which element the data points belong in... (8/3/16)
          -> 16x32x16 case - gets below 5% tol in one step (MF01 solves fully, successfully)
          -> 16x32 case - all iterations solved fine
            -> if LF = 4x8, with 4x ratio, compiled against tweaked libmesh with EquationSystems patch is fine with or without buffer
    -very coarse aux sadj is dying via newton even with superlu...??
    -wtf the linear inv LF doesn't even solve in one step with superlu...??
      -gmres and superlu end up in the same place, at least in terms of QoI: 84387911.200470656 vs 84387911.200470656
      -pre diff-mesh code also has that; see inv_HF_halved_shifted_cont_psi_and_superadj_phys/terminal_output_nvel_realqoi_pe1_n0p1_3p5em2_jacfix2_sofinerer_superlu2.txt
      -> is there something wrong with superlu?
      -pc_type lu -pc_factor_mat_solver_package superlu -pc_factor_nonzeros_along_diagonal
      -ksp_type preonly -pc_type lu -pc_factor_mat_solver_package superlu
          -> neither gets the linear solves in one go, but the one on top doesn't seem seem to solve to residual 0...and yet doesn't break the 8x8x8 tests?
          
split indicator vs error?
  -sadj on HF mesh when want to estimate error, on slightly coarser mesh when just want to find places to refine?
    -> do 2D case with much larger diff between HF and LF meshes? you can totally do finer mesh than bare minimum for not-need-stability...
maybe there's just something about the mixed systems that makes the linear solves harder somehow? like how helmholtz/maxwells doesn't play nice with gmres? maybe the "pc_type ilu" makes a difference in the timing in how much it costs? play with different flags?
  11702 - repeating a 2:1 run with different flags
  11628 - timing if refined in one go? is the effect of initial guess so great?
    -what if you do same-mesh, make LF aniso and with velocity? and refine in one go, direct transfer option off? then timing should be similar...
      -12317 in v1 (MAKE SURE TO UNDO CHANGE IN CONVDIFF_PRIMARY AFTERWARDS)
        -wtf not even first R=0 solve matches...initial residual is same, but then krylov iterations are not...
          -same for R=4.2e-4 (same residual, then krylov iterations differ...)
            -> adapt HF replication was run without ilu precond... -> terminal_output_dbg_10itermax.txt ; if same flags, then lin iters look the same, but then the residuals start diverging...
              -in 2D things are exactly the same...in 3D (8x8x8) with 2D data, starts diverging...tkdiff shows no noticeable differences...
                -matches when updated to new libmesh
        -diff vs cdr forgets to make U=0 along boundaries when touching LF subdomain...eh they all do...

--------------------------------
        
-ksp_monitor_singular_value -ksp_gmres_modifiedgramschmidt -ksp_gmres_restart 500 -pc_type ilu -pc_factor_levels 4 -pc_factor_shift_type nonzero

-pc_type lu -pc_factor_mat_solver_package superlu -pc_factor_nonzeros_along_diagonal
-ksp_type preonly -pc_type lu -pc_factor_mat_solver_package superlu
    
do we really need sadj to be at least as fine as MF mesh? wasn't the point of having regular adjoint on slightly finer mesh so that it wouldn't give 0 when weighted with residual? but here our highest ideal is the HF mesh, so in areas where the MF mesh is refined up to HF, we can't/don't need the adj to give nonzero weight with residual...
  -> no not really...
  
do a run where you use the final MF (and maybe its aux and superadj) on new data and time? vs HF?

interpretations:
-adaptivity is faster than doing HF inv
  -> our HF inv's are too easy
-online-offline - use adaptivity to choose MF that you then solve inverse problem with once data arrives
  -> do you calculate aux and/or superadj with new data or use ones saved from adaptivity?
    -LF and HF on same mesh
      -table 3: single MF iteration (MF + error estimate) sometimes faster than HF inv, but sometimes slower
    -LF and HF on diff meshes (x2 difference)
      -MF inv problems sometimes take longer than HF inv problem...even with significantly fewer DOFs...
        -vikram inquiring list as to whether such mixed models should have a different linear solver...maybe gmres is not appropriate somehow?
        -try a version with similar HF setup (and bcs, and data) as in paper? (can't, qoi region too small to show up on coarse mesh...)
    -LF and HF on diff meshes (x4 difference, superadj on x2 (more error, but probably closer to what would happen in practice?))
      -letting 0.03 step, with buffer, qoi2 run for a while in _v2 -> has trouble solving MF02 inv...
      -terminal_output_4p2em4_adapt_0p05step_0p05tol_flat_HF4x_sadj2x_buffer.txt: -> has trouble solving MF01 inv...
      -2D, HF128x256 : you get all the way to 100% refinement and the estimated relative qoi error stays 30+...ridiculous estimated HF qoi all the way...does adj resid need to stay finer than mixed? or maybe evaluate residuals on HF (project psi and superadj)? ***
      
      we have:
      -single iteration may or may not take longer than HF inv; have cases where MF inv consistently takes less time than HF inv
        -coarsening LF mesh doesn't seem to help (either inv takes more time to solve, or reduction is insufficient (superadj still takes too long, HF problem probably insufficiently nonlinear to keep searching in this direction))
        -having superadj be on coarser mesh than HF introduces additional error
          -seems to be much less accurate (possibly theory needs tweaking...)
          -MF inv seems to have more trouble solving...
      if we stop inquiring to into the diff-mesh line, is table 3 adequate? or do we need to do comparison where final (or all?) MFs and HF get the same initial guess? (technically aux and superadj are linear and so shouldn't depend on init guess for convergence, but it might change the number of linear iters...) if so, do we need to use different data?
      
    -> replace scalar vs field with a 3D x2 case? (both show reduction of DOFs)
      
v1: checking that one step to HF matches invHF...it does in terms of iteration output...and also timing (850 vs 860)...so at least the inverse module and solver options match...is there something about mesh refinement that leaves dofs from previous iterations lying around? is there some housekeeping we've been forgetting that doesn't show up in EquationSystems::n_dofs()?
  -> refining all in one step could potentially expose shenanigans? 
    -2D HF64x128: 1-step total of LF+HF inverse problems < invHF (19 vs 30, superlu)
      -if actually do adaptivity, then none of the inverse probs take longer either... (MF01 and MF02, superlu and gmres)...is there something wrong with refinement in 3D? looks like 2D can also have problems in x4 case...
