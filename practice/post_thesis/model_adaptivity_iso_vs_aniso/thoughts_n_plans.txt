-> inverse prob for LF and HF; to avoid optimization algorithm, solve KKT system
  -> which adjoint system? stabilized adjoint or transposed of stabilized jacobian? for optimization problem where we care about a particular discretization, we want to use the transpose of the stabilized forward as the adjoint...
  -> is the adjoint of the stabilized system even the stabilized adjoint-of-unstabilized?
    -what is the meaning of the adjoint of a stabilized system anyways? the stabilization depends on the discretization...
      -> see supg_analysis.pdf
  -> what does the adaptivity theory rely on?
  
...aren't we inferring for a smooth source term, so regular stabilization should be fine?

debug:
nan residual?? after the linear solve...c doesn't seem to have moved from initial guess, based on qoi...also numerical and analytical jacobians don't match
  -> checking analytical jacobians takes a long time...on 46x33x3 mesh, two jacobians now match...still get nan...
  -> 5x5x3 should be small enough for matlab to read in without freezing...
    -nan whether supg toggled on or off
    -J is not full rank...311/432...fwd J was full rank, so shouldn't be about BCs of fwd+adjoint...
      -> if we view z as a forcing for f, then the gradient equation doesn't have a unique solution? is the regularization insufficient to make the problem well posed cuz it penalizes the gradient? is that why you chose forcing to be zero at boundaries?
      -> if f given homo Diri BCs, then J still not full rank (422/432) (485/504 for 5x6x3 mesh...)
      -> does giving either of the other BCs diri BCs fill up the remaining rank deficit?
        -f and c have homo diri: 352/432 O.o??
        -f and z have homo diri: 311/432
        -something wrong in interior? if all have homo diri and side residual contribution set to zero, still get nan's
          -interior terms look the same as in old cd_all inverse system...
          -matlab says rank is 417/432; if velocity increased to 2.415 (remove e-5 factor), then matlab thinks it's full rank...scaling problem? even with inceased velocity, still get nan...
          -do not get nan if superlu used with regular velocity, but then qoi becomes negative...same for original non-Diri BCs...
            -superlu is not the way to go...on 92x66x5 mesh, even bassi chokes...doesn't finish after 30 minutes...
          -if using inputs for HF for long_channel_stash/qoi2_setup02/HF, recover recorded QoI using superlu, but also get nan residual using default solver; Jacobian on coarser mesh is full rank
          
    system    mesh    variation                             gmres           gmres w/shift           superlu       rank(J)       cond(J)
    nandbg    25x5                                    fails, resid e7                               resid e-17    468/468 **      e3
    nandbg    15x3                                    resid e-14                                    resid e-17    192/192 **      e3
    invLF     5x5x3   f homo diri, no supg            fails, resid nan                              resid e-10    422/432 (same with fixed beta/gradf signs)
    invLF     5x5x3   f homo diri, vel*e5, no supg    fails, resid nan                              resid e-9     429/432
    invLF     5x5x3   f homo diri, vel*e6, no supg    fails, resid nan                              inex newt fails, resid e-8)         
    invLF     46x33x3  f homo diri, vel*e6, no supg                         inex newt fails, (resid e-1) resid e-9
    invLF     46x33x3  f homo diri, vel*e6, no supg, disp 400               inex newt fails, (resid e-2) resid e-8
    invLF     46x33x3  f homo diri, vel*e6, no supg, disp 4000              inex newt fails
    invLF     5x5x3   all homo diri, no supg          fails, resid nan                              resid e-7     417/432
    invLF     5x5x3   all homo diri, vel*e5, no supg  fails, resid nan                              resid e-7     432/432 **      e11
    invLF     5x5x3   all homo diri, vel*e6, no supg                        resid e-1 (9 order reduction)         432/432 **      e9
    invLF     5x5x3   all homo diri, vel*e6, #4 supg                        resid e-2 (10 order reduction)        432/432 **      e9
    invLF     46x33x3  all homo diri, vel*e6, no supg                       resid e-4 (11 order reduction)        
    invLF     5x5x3   all homo diri, vel*e5, no supg, disp 400              resid e-2 (10 order reduction)        432/432 **      e9
    invLF     5x5x3   all homo diri, vel*e5, #4 supg, disp 400              resid e-1 (9 order reduction)         432/432 **      e9
    invLF     5x5x3   all homo diri, vel/decade, no supg, disp 400          resid e-2 (9 order reduction)         432/432 **      e12
    invLF     5x5x3   all homo diri, option 4 supg    fails, resid nan                              resid e-7     417/432  
    invLF     5x5x3   f homo diri, option 4 supg      fails, resid nan                              resid e-9     422/432 
    nandbg    5x5x3   all homo diri, no supg          fails, resid nan                              resid e-7     417/432
    fwd       5x5x3   iso 40                          resid e-7                                     resid e-10    144/144 **      e2  
    nandbg    25x5x5  gave data z-coord, else same    fails, resid nan      resid e-9               resid e-16    TOO LARGE TO READ INTO MATLAB
    nandbg    15x3x3  gave data z-coord, else same    fails, resid nan      resid e-11              resid e-15    768/768 **      e3
    nandbg    15x3x3  gave data z-coord, just f diri                        resid e-12                            768/768 **      e6
    nandbg    15x3x3  gave data z-coord, just f diri, const v=0.5           resid e-11                           
    
    -nondimensionalize, compare current nandebug (put old nandbg params into invLF code?)?
      --wouldn't change the peclet number...is that what's really at the heart of f-homo-diri cases skimming singularity?
      -first implement last nandbg in inv_LF
        -sign on beta*grad_c and cpred-cstar were inconsistent...if match nandbg, then recover same qoi..if flip signs, then newton solve fails...
      -how to nondimensionalize with tensor diff? do you also scale domain?
        -without scaling domain, dividing by tensor*disp -> current nondimensionalization messes up 15x3x3 nandbg qoi...(should be 1.05191)
    -or maybe you really do need to go parallel?
    
    -> add pc_factor_shift_type nonzero:
    ./progname -ksp_monitor_singular_value -ksp_gmres_modifiedgramschmidt -ksp_gmres_restart 500 -pc_type ilu -pc_factor_levels -pc_factor_shift_type nonzero
      -> singularity of J perhaps related to velocity term being too small relative to element size? maybe forward and adjoint, which only differ by sign of velocity, look too similar? no, one acts on adjoint and one acts on state...different columns...
        -> only velocity and reaction use time...
      -> on bassi
          92x66x3
            iso, all homo diri - almost 3 hours of "alive time", but only 6 minutes of "active time"...
            iso, f homo diri - 8.3 hours of "active time", but about 12.2 hours of "alive time"...
            iso, no diri
            aniso, f homo diri
            aniso, no diri
          184x132x4
            iso, f homo diri
            iso, no diri
            aniso, f homo diri
            aniso, no diri
        
bart told karen he has an example that would be applicable to master's and easy to apply in milo?
--> focus on getting the two papers written and submitted this semester before opening more cans...will help you narrow down your ideas and see what work can/should still be done...and to understand what it means to have something finished...you should be expecting to get 2-3 papers from thesis...

karen will be at mit 4/6-7

date for forming committee is a guideline...

----------------------------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------------------------

DO NOT EVER USE HARD RESET EVER AGAIN IT DOESN'T JUST APPLY TO SUBDIRECTORIES IT APPLIES TO THE WHOLE REPO

----------------------------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------------------------

bart didn't seem to have any actual model pairs in mind, just ideas for applications...batteries? also using summer cd(r)...

-if we want to compare linear solves, then need to make sure that linear solves are being solved precisely (especially with iterative solvers!)
-sometimes a newton solve with not converge if linear solves done precisely, but sometimes the looseness of inexact solve can save it (ex: continuation on HF cdr, 600->700 doesn't work if superlu used...)

-write up new error breakdown
-streamline psi-to-superadj
  -how long does it take to set up meshes/system objects? if significant, is there a way to just reassign subdomain IDs? have all the divvy text available and read them in? (re-run from start-to-finish each time new divvy available)
  -reassign subdomain ID without changing current solution? keep that as initial guess?
  -seems like it might be lot less work to read in xda files like in superadj than to read in exo like in psi_MF...psi_MF had a lot of time spent in inverse_map() under FE...
  -solution transfer hopefully doesn't take up too much? (try timing it)
